<!DOCTYPE html>
<html lang="en-US" class="">

<!-- Mirrored from 127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/vecz/vecz by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 22 Sep 2025 18:52:46 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
    <!-- Basics -->
    <title>Vecz Documentation - Guides - oneAPI Construction Kit - Products - Codeplay Developer</title>
    <meta name="description" content="Read the 'Vecz Documentation' for oneAPI Construction Kit 4.0.0 developer guide." />
    <meta name="keywords" content="guides, tutorials, guide, oneapi, construction, kit, risc-v, arm" />
    <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <!-- Open Graph -->
    <meta name="title" property="og:title" content="Vecz Documentation - Guides - oneAPI Construction Kit - Products - Codeplay Developer" />
    <meta name="type" property="og:type" content="website" />
    <meta name="image" property="og:image" content="http://127.0.0.1/assets/img/og-header.png" />
    <meta name="url" property="og:url" content="http://127.0.0.1/" />
    <meta name="description" property="og:description" content="Read the 'Vecz Documentation' for oneAPI Construction Kit 4.0.0 developer guide." />

    <!-- Fonts -->
    <link href="http://127.0.0.1/assets/css/material.css"
          rel="stylesheet preload prefetch"
          as="style" />

    <!-- Fav icon -->
    <link rel="icon" type="image/png" href="http://127.0.0.1/favicon-96x96.png" sizes="96x96" />
    <link rel="icon" type="image/svg+xml" href="http://127.0.0.1/favicon.svg" />
    <link rel="shortcut icon" href="http://127.0.0.1/favicon.ico" />
    <link rel="apple-touch-icon" sizes="180x180" href="http://127.0.0.1/apple-touch-icon.png" />

    <link type="text/css"
          href="http://127.0.0.1/assets/css/responsive.css"
          rel="stylesheet"/>

    <script src="https://cdn.usefathom.com/script.js" data-site="XBWVDDFP" defer></script>

    <!-- Stylesheets -->
    <link type="text/css"
          href="http://127.0.0.1/assets/css/jquery.cookiepolicyprompt.css"
          rel="stylesheet preload prefetch"
          as="style"/>
    <link type="text/css"
          href="http://127.0.0.1/assets/css/jquery.popupdialog.css"
          rel="stylesheet preload prefetch"
          as="style"/>
    <link type="text/css"
          href="http://127.0.0.1/assets/css/dialogs.css"
          rel="stylesheet preload prefetch"
          as="style"/>
    <link type="text/css"
          href="http://127.0.0.1/assets/css/Pages/IndexPage.style.css"
          rel="stylesheet preload prefetch"
          as="style"/>
    <link type="text/css"
          href="http://127.0.0.1/assets/css/Pages/Guides/GuidePageLayout.style.css"
          rel="stylesheet preload prefetch"
          as="style"/>
    <link type="text/css"
          href="http://127.0.0.1/assets/css/Pages/Guides/GuidePageFormatting.style.css"
          rel="stylesheet preload prefetch"
          as="style"/>
    <link type="text/css"
          href="http://127.0.0.1/assets/css/Pages/Guides/GuidePage.style.css"
          rel="stylesheet preload prefetch"
          as="style"/>
    <link type="text/css"
          href="http://127.0.0.1/assets/css/Pages/Products/OneApi/ConstructionKit/OneApiConstructionKitShared.style.css"
          rel="stylesheet preload prefetch"
          as="style"/>
    <link type="text/css"
          href="http://127.0.0.1/assets/css/Pages/Products/OneApi/ConstructionKit/Guide/OneApiConstructionKitGuidePage.style.css"
          rel="stylesheet preload prefetch"
          as="style"/>
    <link type="text/css"
          href="http://127.0.0.1/assets/css/Pages/Products/OneApi/ConstructionKit/Guide/OneApiConstructionKitGuidePage.style.css"
          rel="stylesheet preload prefetch"
          as="style"/>

    <!-- Scripts -->
    <script src="http://127.0.0.1/assets/js/jquery-3.6.3.min.js"></script>
    <script src="http://127.0.0.1/assets/js/jquery.copyright.js"></script>
    <script src="http://127.0.0.1/assets/js/jquery.cookiepolicyprompt.js"></script>
    <script src="http://127.0.0.1/assets/js/jquery.popupdialog.js"></script>
    <script src="http://127.0.0.1/assets/js/Pages/IndexPage.script.js"></script>
    <script src="http://127.0.0.1/assets/js/highlight.min.js"></script>
    <script src="http://127.0.0.1/assets/js/Pages/Guides/jquery.headingsinfocus.js"></script>
    <script src="http://127.0.0.1/assets/js/Pages/Guides/togglebutton.js"></script>
    <script src="http://127.0.0.1/assets/js/Pages/Guides/jquery.resizable.js"></script>
    <script src="http://127.0.0.1/assets/js/Pages/Guides/GuidePage.script.js"></script>

    <script>
        document.querySelectorAll('link').forEach((el) => {this.onload=null;this.rel='stylesheet';});
    </script>
</head>
<body data-deprecated="">

<!-- Header -->
<header>
    <nav class="main">
        <div>
            <a aria-label="Navigation Bar Logo" href="http://127.0.0.1/">
                <div id="codeplay-logo"></div>
            </a>
        </div>
        <div>
            <a title="Click to change production selection">
                <div>
                    <h2>Product</h2>
                    <h1>oneAPI Construction Kit</h1>
                </div>
            </a>
        </div>
        <div>
            <ul>
                <li >
                    <a href="http://127.0.0.1/products/oneapi/construction-kit/home" >
                        <div>

                            <span class="icon material-icons">home</span>

                            <div>Home</div>
                        </div>
                    </a>
                </li>
                <li  class="selected" >
                    <a href="http://127.0.0.1/products/oneapi/construction-kit/guides/" >
                        <div>

                            <span class="icon material-icons">menu_book</span>

                            <div>Guides</div>
                        </div>
                    </a>
                </li>
                <li >
                    <a href="https://github.com/codeplaysoftware/oneapi-construction-kit" target="_blank">
                        <div>

                            <span class="icon material-icons">local_library</span>

                            <div>Repository</div>
                        </div>
                    </a>
                </li>
            </ul>
        </div>
        <div>
            <ul>
                <li>
                    <a href="http://127.0.0.1/support/" title="Get Support">
                        <span class="material-icons">help_outline</span>
                    </a>
                </li>
                <li>
                    <a id="burger"
                       title="Show Navigation Menu">
                        <span class="material-icons">menu</span>
                    </a>
                </li>
            </ul>
        </div>
    </nav>

    <!-- The burger menu, designed for mobile -->
    <div id="burger-menu">
        <ul>
            <li>
                <h1>oneAPI Menu</h1>
                <ul>
                    <li >
                        <a href="http://127.0.0.1/products/oneapi/construction-kit/home"
                           >Home</a>
                    </li>
                    <li  class="selected" >
                        <a href="http://127.0.0.1/products/oneapi/construction-kit/guides/"
                           >Guides</a>
                    </li>
                    <li >
                        <a href="https://github.com/codeplaysoftware/oneapi-construction-kit"
                           target="_blank">Repository</a>
                    </li>
                </ul>
            </li>
            <li>
                <h1>Main Menu</h1>
                <ul>
                    <li>
                        <a href="http://127.0.0.1/">Home</a>
                    </li>
                    <li>
                        <h1>Products</h1>
                        <ul>
                            <li>
                                <a href="http://127.0.0.1/products/computecpp/ce/">ComputeCpp CE</a>
                            </li>
                            <li>
                                <a href="http://127.0.0.1/products/computecpp/pe/">ComputeCpp PE</a>
                            </li>
                            <li>
                                <a href="http://127.0.0.1/products/computesuitercar/ce/">ComputeSuite for R-Car CE</a>
                            </li>
                            <li>
                                <a href="http://127.0.0.1/products/computesuitercar/pe/">ComputeSuite for R-Car PE</a>
                            </li>
                        </ul>
                    </li>
                    <li>
                        <a href="http://127.0.0.1/cookies">Cookie Policy</a>
                    </li>
                    <li>
                        <a href="https://codeplay.com/support/contact">Contact Us</a>
                    </li>
                </ul>
            </li>
        </ul>
    </div>
</header>

<!-- Main element -->
<main>

    <!-- File Container -->
<div class="layout-file guide" id="modules-vecz-vecz">
    <!-- Side Menu -->
    <div class="sticky file-menu-container styled-scroller">
       <div class="nav-padding">
           <!-- Title & Version Selector -->
           <div class="header">
               <h1 class="file-container-title">
                   <span class="material-icons">menu_book</span>Guides
               </h1>
               <div>
                   <!-- Version Selector -->
                   <div class="version-selector ">
                       <div><span class="material-icons">history</span>4.0.0</div>
                       <ul>
                           <li><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/vecz/vecz">4.0.0</a></li>
                           <li><a href="http://127.0.0.1/products/oneapi/construction-kit/3.0.0/guides/modules/vecz/vecz">3.0.0</a></li>
                           <li><a href="http://127.0.0.1/products/oneapi/construction-kit/2.0.0/guides/modules/vecz/vecz">2.0.0</a></li>
                       </ul>
                       <ul>
                           <li><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/vecz/vecz">4.0.0</a></li>
                           <li><a href="http://127.0.0.1/products/oneapi/construction-kit/3.0.0/guides/modules/vecz/vecz">3.0.0</a></li>
                           <li><a href="http://127.0.0.1/products/oneapi/construction-kit/2.0.0/guides/modules/vecz/vecz">2.0.0</a></li>
                       </ul>
                       <ul>
                           <li><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/vecz/vecz">4.0.0</a></li>
                           <li><a href="http://127.0.0.1/products/oneapi/construction-kit/3.0.0/guides/modules/vecz/vecz">3.0.0</a></li>
                           <li><a href="http://127.0.0.1/products/oneapi/construction-kit/2.0.0/guides/modules/vecz/vecz">2.0.0</a></li>
                       </ul>
                   </div>
               </div>
           </div>
           <!-- Menu -->
           <ol class="file-menu">
               <li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/index.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Welcome to oneAPI Construction Kit’s documentation!</a><ol></ol></li>               <li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>oneAPI Construction Kit Overview</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/preface.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Preface</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/introduction.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Introduction</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/introduction/architecture.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>oneAPI Construction Kit Architecture</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/introduction/compiler-view.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Compiler View</a><ol></ol></li></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/hardware.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Mapping ComputeMux to Hardware</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/hardware/memory-requirements.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Memory Requirements</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/hardware/atomic-requirements.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Atomic Requirements</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/hardware/floating-point-requirements.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Floating-Point Requirements</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/hardware/synchronization-requirements.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Synchronization Requirements</a><ol></ol></li></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/runtime.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Runtime Information</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/runtime/computemux-runtime.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>ComputeMux Runtime</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/runtime/driver-requirements.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Driver Requirements</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/runtime/supported-toolchains.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Supported Toolchains</a><ol></ol></li></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/compiler.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Compiler Information</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/compiler/computemux-compiler.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>ComputeMux Compiler</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/compiler/ir.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Intermediate Representation</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/compiler/supported-llvm-versions.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Supported LLVM Versions</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/compiler/non-requirements.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>ComputeMux Compiler Non-Requirements</a><ol></ol></li></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/example-scenarios.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Example Hardware Feature Scenarios</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/example-scenarios/mapping-custom-instructions-to-builtin-functions.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Mapping Custom Instructions To Builtin Functions</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/example-scenarios/mapping-custom-ip-blocks-to-builtin-kernels.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Mapping Custom IP Blocks To Builtin Kernels</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/example-scenarios/how-to-support-large-scratchpad-memories.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>How To Support Large Scratchpad Memories</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/example-scenarios/mapping-algorithms-to-vector-hardware.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Mapping Algorithms To Vector Hardware</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/example-scenarios/refsi-in-kernel-dma.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>RefSi In-Kernel DMA for RISC-V</a><ol></ol></li></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/toolkit.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>oneAPI Construction Kit</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/new-target-quick-start.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Creating a New ComputeMux Target: Quick Start</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/tutorials.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Tutorials</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/tutorials/creating-a-new-hal.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Creating a New HAL</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/tutorials/creating-new-hal/initial-setup.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Initial Setup</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/tutorials/creating-new-hal/kernel-compilation.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Kernel Compilation</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/tutorials/creating-new-hal/runing-clik-tests.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Running clik Tests</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/tutorials/creating-new-hal/skeleton-hal-overview.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Overview of the Skeleton HAL Code</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/tutorials/creating-new-hal/implementing-hal-operations.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Implementing HAL Operations</a><ol></ol></li></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/tutorials/creating-a-new-mux-target.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Creating a New ComputeMux Target</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/tutorials/creating-a-new-mux-target/running-new-target-script.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Running the create_target.py Script</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/tutorials/creating-a-new-mux-target/building-and-running-tests.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Building and Running Tests</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/tutorials/creating-a-new-mux-target/adapting-target-pass-pipeline.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Adapting the Pass Pipeline for the Target</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/tutorials/creating-a-new-mux-target/extending-it-further.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Extending it Further</a><ol></ol></li></ol></li></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/reference-silicon.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Codeplay Reference Silicon</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/reference-silicon/overview.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Codeplay Reference Silicon Overview</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/reference-silicon/command-processor.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Command Processor Reference</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/reference-silicon/dma-controller.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>DMA Controller Reference</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/reference-silicon/dma-programming-guide.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>DMA Programming Guide</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/reference-silicon/driver-interface.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>RefSi Driver Interface</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/overview/reference-silicon/mapping-opencl-to-refsi.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>How The Platform Maps to SYCL and OpenCL</a><ol></ol></li></ol></li></ol></li>               <li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/getting-started.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Getting Started</a><ol></ol></li>               <li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/specifications.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Specifications</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/specifications/versioning.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Versioning Scheme</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/specifications/mux-runtime-spec.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>ComputeMux Runtime Specification</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/specifications/mux-compiler-spec.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>ComputeMux Compiler Specification</a><ol></ol></li></ol></li>               <li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/developer-guide.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Developer Guide</a><ol></ol></li>               <li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/tutorials.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Tutorials</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/tutorials/adding-a-custom-builtins-extension.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Adding A Custom Builtins Extension</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/tutorials/custom-lowering-work-item-builtins.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Custom Lowering Work-Item Builtins</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/tutorials/adding-target-specific-metadata.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Adding Target-Specific Metadata</a><ol></ol></li></ol></li>               <li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/design.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Design</a><ol></ol></li>               <li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>OpenCL</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl/cmake.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>OpenCL CMake</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl/computemux_mapping.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>How OpenCL Concepts Are Mapped Onto ComputeMux</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl/extension.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>OpenCL Extensions</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl/extension/cl_codeplay_kernel_debug.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Kernel Debug - cl_codeplay_kernel_debug</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl/extension/cl_codeplay_extra_build_options.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Extra Build Options - cl_codeplay_extra_build_options</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl/extension/cl_codeplay_kernel_exec_info.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Kernel Exec Info - cl_codeplay_kernel_exec_info</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl/extension/cl_codeplay_performance_counters.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Performance Counters - cl_codeplay_performance_counters</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl/extension/cl_codeplay_soft_math.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Soft Math - cl_codeplay_soft_math</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl/extension/cl_codeplay_wfv.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Whole Function Vectorization - cl_codeplay_wfv</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl/extension/cl_intel_unified_shared_memory.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>USM - cl_intel_unified_shared_memory</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl/extension/cl_intel_required_subgroup_size.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Required subgroup sizes for kernels  - cl_intel_required_subgroup_size</a><ol></ol></li></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl/external-extensions.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>OpenCL External Extensions</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl/icd-loader.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>OpenCL ICD Loader</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl/intercept.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>OpenCL Intercept Layer</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl/tools.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Tools</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl/test.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Tests</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/cl/test/unitcl.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>UnitCL</a><ol></ol></li></ol></li></ol></li>               <li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/source/vk.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Vulkan</a><ol></ol></li>               <li class="selected"><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Modules</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/builtins.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Builtins</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/builtins/abacus.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Abacus</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/builtins/libimg.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Image Library</a><ol></ol></li></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/mux.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>ComputeMux</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/mux/changes.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Change Log</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/mux/compiler.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Compiler</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/mux/cmake.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>CMake</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/mux/bumping-the-spec.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Bumping the Specification Version</a><ol></ol></li></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/host.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Host CPU</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/mux/targets/host/extension/cl_codeplay_host_builtins.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>cl_codeplay_host_builtins</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/mux/targets/host/extension/cl_codeplay_set_threads.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>cl_codeplay_set_threads</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/mux/targets/host/lit.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Host lit test suite</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/mux/targets/host/debug.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Host Debug Features</a><ol></ol></li></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/riscv.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>RISC-V</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/compiler.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Compiler</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/compiler/overview.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Overview</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/compiler/utils.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Compiler Utilities</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/compiler/tools.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Tools</a><ol><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/compiler/tools/muxc.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>muxc</a><ol></ol></li></ol></li></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/loader.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>ELF loader</a><ol></ol></li><li class="selected"><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/vecz.html"><div class="icon"><span class="icon material-icons">subdirectory_arrow_right</span></div>Vecz</a><ol><li class="selected focused"><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/vecz/vecz.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Vecz Documentation</a><ol></ol></li></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/spirv-ll.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>spirv-ll</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/debug.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Debug Module</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/cargo.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Cargo Module</a><ol></ol></li><li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/metadata.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Metadata API</a><ol></ol></li></ol></li>               <li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/cmake.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>CMake Development</a><ol></ol></li>               <li class=""><a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/scripts.html"><div class="icon"><span class="icon material-icons">arrow_forward</span></div>Scripts</a><ol></ol></li>           </ol>
       </div>
    </div>
    <!-- Core Content -->
    <div>
        <!-- File Content -->
        <div id="content-container" class="nav-padding">
            <article class="file-content-container">
                <header>
                    <!-- Deprecated Notice -->

                    <div class="title">
                        <a class="header-link" href="#vecz-documentation">
                            <h1>Vecz Documentation</h1>
                        </a>
                        <div>
                            <a href="#rate" title="Rate this guide">
                                <i class="material-icons">thumb_up</i>
                            </a>

                            <a target="_blank" href="https://github.com/codeplaysoftware/oneapi-construction-kit/blob/main/doc/modules/vecz/vecz.md" rel="noopener" title="Contribute to this guide">
                                <i class="material-icons">edit</i>
                            </a>

                            <a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/spirv-ll" title="Goto the next guide">
                                <i class="material-icons">arrow_forward_ios</i>
                            </a>
                        </div>
                    </div>

                </header>

                <div class="formatted-text">
                    <a id="top"></a>
                    <html><body><div class="document">
<div>
<div class="tex2jax_ignore mathjax_ignore section" id="vecz-documentation">

<p>Codeplay’s Vecz is a library based on LLVM that allows vectorization of SPMD
programs such as OpenCL kernels.</p>
<p>Vecz is automatically built during the oneAPI Construction Kit build process
(only if a runtime compiler is found) but needs to be manually enabled to be
used during the kernel compilation process. This is done by providing the
<code class="docutils literal notranslate">-cl-wfv={always|auto}</code> option before running any OpenCL program.</p>
<p>Vecz ships with a standalone tool called <code class="docutils literal notranslate">veczc</code>. This tool will consume LLVM IR</p>
<ul class="simple">
<li><p>in bitcode or textual format, producing vectorized output.</p></li>
</ul>
<div class="section" id="design-ideas">
<a class="header-link" href="#design-ideas"><h2 id="design-ideas">Design ideas</h2><span class="material-icons">link</span></a>
<p>Vecz’s design is based on the automatic whole function vectorization research
by <a class="reference external" href="http://dblp.uni-trier.de/pers/hd/k/Karrenberg:Ralf">Ralf Karrenberg</a>, titled “Automatic SIMD Vectorization of SSA-based
Control Flow Graphs”, and a combination of other papers referenced at various
places in this document. While the process followed by Vecz is not exactly the
same, understanding the research would help to understand Vecz better.</p>
</div>
<div class="section" id="supporting-infrastructure">
<a class="header-link" href="#supporting-infrastructure"><h2 id="supporting-infrastructure">Supporting infrastructure</h2><span class="material-icons">link</span></a>
<p>Vecz relies on certain other classes and functions provided by
<code class="docutils literal notranslate">compiler::utils</code>.  The <code class="docutils literal notranslate">BuiltinInfo</code> interface is used to ascertain certain
properties of OpenCL builtin functions such as whether a particular function
has a vector equivalent, or whether it is a work item ID query. Specific
implementations of the interface are provided for OpenCL.</p>
<p>Before running vecz, it is recommended to run the
<code class="docutils literal notranslate">compiler::utils::OptimalBuiltinReplacementPass</code>. This replaces certain builtin
calls with LLVM instructions or intrinsics that perform the equivalent
operation, which enables later optimizations to work with them (which applies
both to LLVM’s own optimization passes that vecz runs, and to some of vecz’s
own transform passes). Furthermore, it allows these builtins to be widened
arbitrarily, without being limited to the widths available as OpenCL builtins.</p>
<p>If a target intends to use the <code class="docutils literal notranslate">compiler::utils::WorkItemLoopsPass</code> after Vecz,
it is important to ensure that, <strong>before vecz</strong>,  all calls to barrier-like
functions in the full nested kernel call-graph are given unique barrier IDs.
Note that this effectively mandates full inlining of all functions containing
barrier-like calls.</p>
<p>This is necessary because vectorization can considerably affect control flow,
so the ordering of the barriers in the function may change. If the
<code class="docutils literal notranslate">WorkItemLoopsPass</code> needs to combine two different versions of the same kernel
into a single scheduled kernel, it is vital that direct correspondence of the
barrier calls is maintained.</p>
<p>Users can run the <code class="docutils literal notranslate">compiler::utils::PrepareBarriersPass</code>, which satisfies these
requirements.</p>
<p>The <code class="docutils literal notranslate">vecz::RunVeczPass</code> does not delete the original scalar kernel after
vectorization, nor does it transfer the scalar kernel name to the vectorized
function.</p>
</div>
<div class="section" id="target-specialization">
<a class="header-link" href="#target-specialization"><h2 id="target-specialization">Target specialization</h2><span class="material-icons">link</span></a>
<p>Vecz provides an interface, <code class="docutils literal notranslate">vecz::TargetInfo</code>, that allows the vectorizer to make
target-dependent decisions. This is retrieved via an analysis pass:
<code class="docutils literal notranslate">vecz::TargetInfoAnalysis</code>. Targets may override the <code class="docutils literal notranslate">vecz::TargetInfo</code>
constructed by this Analysis. The interface has a default implementation, which
may be overridden.</p>
<p>Targets can override:</p>
<ul class="simple">
<li><p>Builder functions for all of the various forms of memory
operation that vecz can output: loads and stores in masked or unmasked forms;
contiguous access; interleaved access; scatter/gather access. Targets may want
to provide their own intrinsics for these operations, if they exist.</p></li>
<li><p>Builder functions for special forms of vector shuffles on scalable vectors,
namely “inner” and “outer” broadcasts (meaning the duplication of each vector
element <code class="docutils literal notranslate">n</code> times, and the duplication of the entire vector <code class="docutils literal notranslate">n</code> times), as
well as vectorized scalable extract and insert instructions (which vectorize
to a pick or replacement of every nth element to/from a narrower vector).
Since there are no LLVM instructions to efficiently perform these operations
on scalable vectors, the default implementation involves writing to memory and
reading it back, which is likely to be suboptimal.</p></li>
<li><p>Builder function to construct the vector length argument of predicated vector
instructions, on targets that support this feature.</p></li>
<li><p>Functions to support the Interleaved Groups Combining Pass.</p></li>
<li><p>A function to support the SIMD Width Analysis that returns the widest
vectorization factor possible for a given set of values.</p></li>
<li><p>A function to compute the preferred vector width of a given scalar type. The
packetizer can use this to emit multiple vectors per scalar-kernel value,
instead of a single wider vector. The default implementation is based on the
bit width of a single vector register (from <code class="docutils literal notranslate">llvm::TargetTransformInfo</code>).</p></li>
</ul>
<p>For full details, see the documentation of the <code class="docutils literal notranslate">vecz/target_info.h</code> header file.</p>
</div>
<div class="section" id="vectorization-process">
<a class="header-link" href="#vectorization-process"><h2 id="vectorization-process">Vectorization process</h2><span class="material-icons">link</span></a>
<ul class="simple">
<li><p>Clone the kernel function</p></li>
<li><p>Analyze the kernel function to determine if it has a pattern not prone to
being vectorized</p></li>
<li><p>Run preparation passes</p></li>
<li><p>Perform control-flow to data-flow conversion (to handle divergent CFGs)</p></li>
<li><p>Scalarize the kernel if desired/needed</p></li>
<li><p>Run pre-packetization “middle optimization” passes</p></li>
<li><p>Determine the optimal SIMD width for the kernel</p></li>
<li><p>Packetize the kernel</p></li>
<li><p>Perform optimizations and cleanup</p></li>
<li><p>Define internal builtins</p></li>
</ul>
</div>
<div class="section" id="uniform-analysis">
<a class="header-link" href="#uniform-analysis"><h2 id="uniform-analysis">Uniform Analysis</h2><span class="material-icons">link</span></a>
<p>Instructions in a kernel function may be uniform (i.e. they evaluate to the
same value or have the same side-effects on all lanes) or varying. Varying
instructions usually have a data dependency on either the global ID or the local
ID of the work-item executing the kernel. As an example, in the following kernel
the store to the global memory, as well as the calculation of the address for
the store, are varying instructions depending on the global ID of the work-item.
The multiplication of <code class="docutils literal notranslate">in</code> by 2 on the other hand is uniform, since it is the
same across all the work-items.</p>
<pre><code class="language-c">kernel void fn(int in, global int *out) {
  size_t tid = get_global_id(0);
  in = in * 2;
  out[tid] = in;
}
</code>
</pre>
<p>Assuming to vectorize on the x dimension, after packetization, functions calls
like <code class="docutils literal notranslate">get_global_id(0)</code> or <code class="docutils literal notranslate">get_local_id(0)</code> will return vectors of consecutive
indices, which will allow us to packetize the store into a vector store.</p>
<p>On architectures that support both scalar and vector instructions we do not want
to packetize uniform instructions, as each vector lane will perform the same
operation on the same data and return the same result. Instead, we want to keep
uniform instructions scalar (i.e. keep the original instructions untouched), and
broadcast their value into a vector when necessary.</p>
<p>In order to differentiate between the varying and the uniform instructions,
we have implemented an analysis pass called the <code class="docutils literal notranslate">Uniform Analysis</code>. This
analysis starts by finding “vector roots” in the function. By “roots” we mean
instructions (usually function calls) that we know to be varying. For example,
work-item ID related functions, or packetized arguments in non-kernel functions
are some common vector roots. Each root and its users are recursively marked as
varying. Marking a value happens before marking its users, so that use cycles
(e.g. phi nodes) do not cause infinite recursion. The instructions remaining
after this process are considered to be uniform.</p>
<p>In the previous example kernel, the vector root used is the call to the
<code class="docutils literal notranslate">get_global_id(0)</code> function. Starting from that point and then recursively
going through its users and their users etc. We recursively mark the address
calculation (<code class="docutils literal notranslate">getelementptr</code>) for the output and the store to the output as
varying too. The <code class="docutils literal notranslate">in</code> value and its multiplication are not marked as varying
since they are not using any varying values, they are being used by one. We
should note here that under special cases, such as an <code class="docutils literal notranslate">alloca</code> instruction that
is stored into by a varying store, we might mark some instructions as varying
just because they are used by a varying instruction but in the general case we
do not.</p>
<blockquote>
<div><p>The relevant classes and functions can be found in
<code class="docutils literal notranslate">source/include/analysis/uniform_value_analysis.h</code> and
<code class="docutils literal notranslate">source/analysis/uniform_value_analysis.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="stride-analysis">
<a class="header-link" href="#stride-analysis"><h2 id="stride-analysis">Stride Analysis</h2><span class="material-icons">link</span></a>
<p>Memory operations can access their data in several different patterns, as a
function of the work item ID, categorized as:</p>
<ul class="simple">
<li><p>Uniform: data is accessed from the same address for all work items;</p></li>
<li><p>Contiguous: data is accessed sequentially with no gaps;</p></li>
<li><p>Strided: data is accessed linearly but spaced apart with a constant or
uniform stride;</p></li>
<li><p>Divergent: data is accessed with no discernible pattern.</p></li>
</ul>
<p>The stride analysis traverses address computation expressions, to ascertain
which kind of memory access is required, computing any constant strides
encountered. Uniform but variable strides are not computed during the analysis,
because doing so would require creating new instructions in the function, which
is at odds with the idea of an analysis pass. However, it is usually sufficient
to know that access is linear, without needing to know its actual value. When a
transform pass wishes to make use of the actual value, it can call the
<code class="docutils literal notranslate">manifest()</code> function of the analysis, which will traverse its internal dataset
and create any instructions required. Note that pointers to these instructions
will survive until the analysis is invalidated.</p>
<p>This analysis uses the result of <a class="reference internal" href="#uniform-analysis"><span class="std std-doc">Uniform Analysis</span></a>.</p>
<blockquote>
<div><p>The relevant classes and functions can be found in
<code class="docutils literal notranslate">source/include/analysis/stride_analysis.h</code> and
<code class="docutils literal notranslate">source/analysis/stride_analysis.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="packetization-analysis">
<a class="header-link" href="#packetization-analysis"><h2 id="packetization-analysis">Packetization Analysis</h2><span class="material-icons">link</span></a>
<p>The packetizer needs to know which instructions require packetization in
advance, for optimal functioning. An instruction that has been marked as
varying by the <a class="reference internal" href="#uniform-analysis"><span class="std std-doc">Uniform Analysis</span></a> may or may not require
packetization, since some varying values will form an expression computing
the address of a contiguous or strided memory operation. Therefore, this
analysis starts at the function’s vector leaves, and works backwards through
operands, recursively marking values for packetization. When a contiguous or
strided memory operation is encountered, its address operand is not
followed. This allows a more accurate estimation of packetization requirements
prior to actual packetization, which is useful for the
<a class="reference internal" href="#simd-width-analysis"><span class="std std-doc">SIMD Width Analysis</span></a>.</p>
<p>This analysis uses the result of <a class="reference internal" href="#stride-analysis"><span class="std std-doc">Stride Analysis</span></a>.</p>
<blockquote>
<div><p>The relevant classes and functions can be found in
<code class="docutils literal notranslate">source/include/analysis/packetization_analysis.h</code> and
<code class="docutils literal notranslate">source/analysis/packetization_analysis.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="control-flow-graph-analysis">
<a class="header-link" href="#control-flow-graph-analysis"><h2 id="control-flow-graph-analysis">Control Flow Graph Analysis</h2><span class="material-icons">link</span></a>
<p>Another useful analysis we employ is the Control Flow Graph (CFG) Analysis. As
the name suggests, it analyzes the control flow graph to store useful
information about blocks and loops such as what loop does a block live in and
what are the lcssa values of a loop (values that are live through a loop).</p>
<p>The analysis works by iterating over the basic blocks, create a tag for each
block, and if the block belongs in a loop, then create a tag for that loop (if
one does not yet exist) and mark the loop as owning the block.</p>
<p>If in the process of visiting the blocks we encounter a divergent branch, then
we say that the CFG needs to be converted into a Data-Flow Graph (see the
<a class="reference internal" href="#control-flow-conversion-pass"><span class="std std-doc">Control Flow Conversion</span></a> section).</p>
<blockquote>
<div><p>The relevant classes and functions can be found in
<code class="docutils literal notranslate">source/include/analysis/control_flow_analysis.h</code> and
<code class="docutils literal notranslate">source/analysis/control_flow_analysis.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="divergence-analysis">
<a class="header-link" href="#divergence-analysis"><h2 id="divergence-analysis">Divergence Analysis</h2><span class="material-icons">link</span></a>
<blockquote>
<div><p>Formally known as <code class="docutils literal notranslate">Rewire Target Analysis</code>.</p>
</div></blockquote>
<p>This analysis is used to find all the information regarding divergence in a CFG.
It uses as a pre-requisite the <a class="reference internal" href="#uniform-analysis"><span class="std std-doc">Uniform Analysis</span></a> to know
which instructions are varying when we first evaluate the CFG. Those
instructions are the basis to find divergent branches, which are branches whose
operands are varying. We name blocks having such instructions <code class="docutils literal notranslate">div_causing</code>.
The analysis works by iterating over all the branches in the CFG until no more
new <code class="docutils literal notranslate">div_causing</code> blocks are found.
When we find a <code class="docutils literal notranslate">div_causing</code> block, we first compute the divergent path that
this block creates. This divergent path contains all the blocks from the
<code class="docutils literal notranslate">div_causing</code> block to the post dominator of the latter. All the blocks that
belong in a divergent path may need to have their instructions marked varying,
in the case where they might be used outside the divergent path and thus need
to be packetized.
We then find all the join points of the <code class="docutils literal notranslate">div_causing</code> block. Such blocks have
disjoint paths from the <code class="docutils literal notranslate">div_causing</code> block. These blocks are called <code class="docutils literal notranslate">blend</code>
blocks and will need to have their PHI nodes transformed into select
instructions because their path will be linearized. These blocks also need to
have their PHI nodes marked as varying.
After we have processed the <code class="docutils literal notranslate">div_causing</code> block, we must find if this block
makes a loop divergent. A loop is divergent if it is possible that some work
items leave the loop at an exit, while others keep iterating. In essence, this
means that a divergent branch has no post-dominator in the loop. We also mark
all the exits of the loop where <em>some</em> work items may leave as divergent because
they will need to be linearized.
Finally, we compute <code class="docutils literal notranslate">by_all</code> blocks which are blocks that need not be predicated
because no divergence is present when they are executed.</p>
<blockquote>
<div><p>The relevant functions can be found in
<code class="docutils literal notranslate">source/include/analysis/divergence_analysis.h</code> and
<code class="docutils literal notranslate">source/analysis/divergence_analysis.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="liveness-analysis">
<a class="header-link" href="#liveness-analysis"><h2 id="liveness-analysis">Liveness Analysis</h2><span class="material-icons">link</span></a>
<p>This analysis is used to determine the set of live values at any point in the
program. A value becomes “live” at its definition and remains live until all of
its uses have been encountered. The result of this analysis provides an info
object for every basic block in the program, that contains the “Live In” set
(i.e. the values that are live at the start of the Basic Block, including all
of its PHI nodes), and the “Live Out” set (i.e. the values that are still live
at the end of the block). By iterating backwards over a Basic Block, starting
from the Live Outs, one can determine the set of values that are live at any
point in the program.</p>
<p>The implementation is based on Section 5.2 of the paper “Computing Liveness Sets
for SSA-Form Programs.” by Florian Brandner, Benoit Boissinot, Alain Darte,
Benoît Dupont de Dinechin, Fabrice Rastello.</p>
<p>This analysis is used by <a class="reference internal" href="#branch-on-superword-condition-code"><span class="std std-doc">BOSCC</span></a>, and by
<a class="reference internal" href="#simd-width-analysis"><span class="std std-doc">SIMD Width Analysis</span></a>.</p>
<blockquote>
<div><p>The relevant classes and functions can be found in
<code class="docutils literal notranslate">source/include/analysis/liveness_analysis.h</code> and
<code class="docutils literal notranslate">source/analysis/liveness_analysis.cpp</code></p>
</div></blockquote>
</div>
<div class="section" id="simd-width-analysis">
<a class="header-link" href="#simd-width-analysis"><h2 id="simd-width-analysis">SIMD Width Analysis</h2><span class="material-icons">link</span></a>
<p>This analysis is used to estimate the optimal vectorization width, depending on
the contents of the kernel. The current strategy is a two-stage process: first
we find the widest used varying value type, disregarding types that make up less
than a small proportion of the program according to some tolerance threshold.
The SIMD width computed is the number of elements of this type that will fit
into a single vector register. Then we analyze the program using the
<a class="reference internal" href="#liveness-analysis"><span class="std std-doc">Liveness Analysis</span></a> to estimate the maximum SIMD width that
will fit into vector registers, if it is wider than the previously computed
result. This allows vectorization to produce values that will not necessarily
fit into single vector registers, but will fit across multiple registers after
legalization.</p>
<p>SIMD Width Analysis is performed only when vectorization is set to automatic
(either by using the <code class="docutils literal notranslate">-cl-wfv=auto</code> option or by passing <code class="docutils literal notranslate">bool Auto=true</code> to
<code class="docutils literal notranslate">Vectorizer::vectorize()</code>). The analysis is performed after control flow
conversion, so that any changes made by this or prior passes will be taken into
account.</p>
<p>This analysis uses the result of
<a class="reference internal" href="#packetization-analysis"><span class="std std-doc">Packetization Analysis</span></a>.</p>
<blockquote>
<div><p>The relevant classes and functions can be found in
<code class="docutils literal notranslate">source/include/analysis/simd_width_analysis.h</code> and
<code class="docutils literal notranslate">source/analysis/simd_width_analysis.cpp</code></p>
</div></blockquote>
</div>
<div class="section" id="vectorizability-analysis">
<a class="header-link" href="#vectorizability-analysis"><h2 id="vectorizability-analysis">Vectorizability Analysis</h2><span class="material-icons">link</span></a>
<p>This is not an analysis in the traditional sense but more of a filter for
kernels that we know we will not be able to vectorize. There are a number of
cases that we cannot handle in Vecz, such as kernels containing specific atomic
instructions, functions returning vector results, or specific OpenCL builtins.
By checking for these conditions early in the vectorization process we can save
on compile time and also avoid accidentally generating an incorrectly vectorized
kernel.</p>
<blockquote>
<div><p>The relevant functions can be found in
<code class="docutils literal notranslate">source/include/vectorization_context.h</code> and
<code class="docutils literal notranslate">source/vectorization_context.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="reachability-analysis">
<a class="header-link" href="#reachability-analysis"><h2 id="reachability-analysis">Reachability Analysis</h2><span class="material-icons">link</span></a>
<p>This is a utility class created to speed up CFG reachability queries required by
<a class="reference internal" href="#branch-on-superword-condition-code"><span class="std std-doc">BOSCC</span></a>. It is not an analysis pass managed
by LLVM, but must be created manually where required. The algorithm is based on
an Open Proceedings paper entitled “Reachability Queries in Very Large Graphs: A
Fast Refined Online Search Approach” by Renê R. Veloso, Loïc Cerf, Wagner Meira
Jr, Mohammed J. Zaki. In addition to that approach, dominator and post-dominator
trees are used to further accelerate the process.</p>
<p>The reachability data structure must be constructed from a directed acyclic
graph. Backedge traversal is a case not yet handled.</p>
<blockquote>
<div><p>The relevant functions can be found in <code class="docutils literal notranslate">source/include/reachability.h</code> and
<code class="docutils literal notranslate">source/reachability.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="preparation-passes">
<a class="header-link" href="#preparation-passes"><h2 id="preparation-passes">Preparation Passes</h2><span class="material-icons">link</span></a>
<p>We employ a set of preparation passes that includes both optimization passes,
such as the Mem2Reg pass discussed later on, and passes necessary to generate IR
that Vecz can handle:</p>
<ul class="simple">
<li><p>Dominator Tree Wrapper Pass (from LLVM)</p></li>
<li><p>Loop Info Wrapper Pass (from LLVM)</p></li>
<li><p>Switch Lowering Pass (from LLVM)</p></li>
<li><p>Function Exit Nodes Unification Pass (from LLVM)</p></li>
<li><p>Builtin Inlining Pass (from Vecz, described below)</p></li>
<li><p>Promote Memory To Register Pass (from LLVM)</p></li>
<li><p>Basic Mem2Reg Pass (from Vecz, described below)</p></li>
<li><p>Instruction Combining Pass (from LLVM)</p></li>
<li><p>Dead Code Elimination Pass (from LLVM)</p></li>
<li><p>Pre-linearization Pass (from Vecz, described below)</p></li>
<li><p>Instruction Combining Pass (again, to deal with Pre-linearization changes)</p></li>
<li><p>CFG Simplification Pass (from LLVM)</p></li>
<li><p>Unify Function Exit Nodes Pass (from LLVM)</p></li>
<li><p>Loop Simplification Pass (from LLVM)</p></li>
<li><p>Loop Rotate Pass (from LLVM)</p></li>
<li><p>Simplify Infinite Loop Pass (from Vecz, described below)</p></li>
<li><p>Induction Variable Simplification Pass (from LLVM)</p></li>
<li><p>Early CSE Pass (from LLVM)</p></li>
<li><p>LCSSA Pass (from LLVM - restores LCSSA form if broken by Early CSE)</p></li>
</ul>
<blockquote>
<div><p>The relevant classes and functions can be found in <code class="docutils literal notranslate">vectorizer.cpp</code>, as
well as <code class="docutils literal notranslate">builtin_inlining_pass.h</code>, <code class="docutils literal notranslate">builtin_inlining_pass.cpp</code>,
<code class="docutils literal notranslate">basic_mem2reg_pass.h</code>, and <code class="docutils literal notranslate">basic_mem2reg_pass.cpp</code> for the Vecz
passes.</p>
</div></blockquote>
<div class="section" id="builtin-inlining-pass">
<a class="header-link" href="#builtin-inlining-pass"><h3 id="builtin-inlining-pass">Builtin Inlining Pass</h3><span class="material-icons">link</span></a>
<p>The Builtin Inlining pass replaces calls to OpenCL builtins with an inline
version of the builtin. This is done because the generic approach that we follow
for getting the scalar or vector equivalent of a builtin (described later in the
<a class="reference internal" href="#packetizing-opencl-builtins"><span class="std std-doc">Packetizing OpenCL Builtins</span></a> section) does not
work for all of them, so instead we bring the implementation in the same module
as the kernel and let the vectorizer vectorize it. More details can be found in
the <a class="reference internal" href="#vectorizing-builtin-functions"><span class="std std-doc">Vectorizing Builtin Functions</span></a> section.</p>
<blockquote>
<div><p>The relevant class can be found in
<code class="docutils literal notranslate">source/include/transform/builtin_inlining_pass.h</code> and
<code class="docutils literal notranslate">source/transform/builtin_inlining_pass.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="basic-mem2reg-pass">
<a class="header-link" href="#basic-mem2reg-pass"><h3 id="basic-mem2reg-pass">Basic Mem2Reg Pass</h3><span class="material-icons">link</span></a>
<p>The Basic Mem2Reg pass performs <code class="docutils literal notranslate">alloca</code> promotions, similar to how the LLVM
Mem2Reg pass operates. Of course, there are a number of requirements that an
<code class="docutils literal notranslate">alloca</code> and its users need to fulfill before it is possible to perform such an
optimization but the general idea is this: we first check if it is possible
to determine the value (as an LLVM Value, not necessarily as a compile time
constant value) stored in the <code class="docutils literal notranslate">alloca</code>, and if it is the case, then users of
the <code class="docutils literal notranslate">alloca</code> are updated to use the stored value directly, instead of loading it
from the <code class="docutils literal notranslate">alloca</code>.</p>
<p>The Basic Mem2Reg is somewhat simpler than LLVM’s own Promote Memory To Register
Pass, and as a result more strict in what it will promote. However, it is able
to promote some <code class="docutils literal notranslate">alloca</code>s that LLVM’s own pass cannot, for instance where there
are bitcasts involved.</p>
<blockquote>
<div><p>The pass can be found in <code class="docutils literal notranslate">basic_mem2reg_pass.h</code> and <code class="docutils literal notranslate">basic_mem2reg_pass.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="pre-linearization-pass">
<a class="header-link" href="#pre-linearization-pass"><h3 id="pre-linearization-pass">Pre-linearization Pass</h3><span class="material-icons">link</span></a>
<p>This pass transforms simple <code class="docutils literal notranslate">if-then</code> and <code class="docutils literal notranslate">if-then-else</code> constructs by hoisting
their contents out into the parent scope, when it determines that the cost of
executing the instructions is less than the cost of the branches. This also takes
into account of the extra branching logic that will be inserted by
<a class="reference internal" href="#branch-on-superword-condition-code"><span class="std std-doc">BOSCC</span></a> during Control Flow Conversion.</p>
<p>The CFG itself is not modified, instead being left for LLVM’s CFG Simplification
Pass to tidy up.</p>
<blockquote>
<div><p>The pass can be found in <code class="docutils literal notranslate">source/transform/pre_linearize_pass.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="simplify-infinite-loop-pass">
<a class="header-link" href="#simplify-infinite-loop-pass"><h3 id="simplify-infinite-loop-pass">Simplify Infinite Loop Pass</h3><span class="material-icons">link</span></a>
<p>The Simplify Infinite Loop pass checks the CFG for infinite loops that may still
be present after the LLVM loop simplifications passes we call. This pass is
necessary for VECZ to make all loops have the same layout, i.e. in this case at
least one exit block, as handling infinite loops within the
<a class="reference internal" href="#control-flow-conversion-pass"><span class="std std-doc">Control Flow Conversion Pass</span></a> would add too much
overhead.</p>
<p>This pass is a loop pass and will check, for each loop, if exit blocks are
present. If not, it means the loop cannot terminate (as it cannot be exited) so
we have to mutate it. It then tries to find the unique return block of the
function (it should only have one as we call <code class="docutils literal notranslate">UnifyFunctionExitNodesPass</code> prior
to this pass to make sure we do have only one return block). This return block
will be the exit block of the infinite loop after mutation. After finding the
latter, we add a conditional branch to the latch that will either branch to the
header or to the return block. The condition of that conditional branch will
actually always be true such that it will still always branch to the loop
header to respect the semantic of the original program. Finally, the pass
updates the PHI nodes in the return block by adding an incoming block to them,
which is the latch of the infinite loop. It also adds new PHI nodes for uses in
the return block that may be defined after the infinite loop, for which adding
the edge from the infinite loop to the return block may break the SSA form.</p>
<blockquote>
<div><p>The pass can be found in <code class="docutils literal notranslate">source/transform/simplify_infinite_loop_pass.cpp</code>.</p>
</div></blockquote>
</div>
</div>
<div class="section" id="remove-intptr-pass">
<a class="header-link" href="#remove-intptr-pass"><h2 id="remove-intptr-pass">Remove Intptr Pass</h2><span class="material-icons">link</span></a>
<p>This pass scans for <code class="docutils literal notranslate">PtrToInt</code> casts that can be eliminated and converted into
bitcasts or GEP instructions. It is able to eliminate a <code class="docutils literal notranslate">PtrToInt</code> in the
following cases:</p>
<ul class="simple">
<li><p>A PtrToInt followed by an IntToPtr, which is replaced by a pointer cast;</p></li>
<li><p>A PtrToInt used by a PHI node, in which case the PHI node is replaced
by one of the pointer type;</p></li>
<li><p>A PtrToInt where the pointer type is <code class="docutils literal notranslate">i8*</code>, followed by an integer add or
subtract, in which case it is replaced by a GEP.</p></li>
</ul>
<p>Removing intptr casts makes it possible for uniform pointer strides to be
identified.</p>
<blockquote>
<div><p>The pass can be found in <code class="docutils literal notranslate">source/transform/remove_intptr_pass.cpp</code></p>
</div></blockquote>
</div>
<div class="section" id="squash-small-vectors-pass">
<a class="header-link" href="#squash-small-vectors-pass"><h2 id="squash-small-vectors-pass">Squash Small Vectors Pass</h2><span class="material-icons">link</span></a>
<p>This pass looks for loads and stores of vector types that fit into a legal
integer, where packetization would result in non-contiguous access, and replaces
them with loads or stores of an integer scalar of the same size (where alignment
requirements permit). This allows more efficient generation of scatter/gather or
interleaved memory operations on these types.</p>
<blockquote>
<div><p>The pass can be found in <code class="docutils literal notranslate">source/transform/squash_small_vectors_pass.cpp</code></p>
</div></blockquote>
</div>
<div class="section" id="scalarization-pass">
<a class="header-link" href="#scalarization-pass"><h2 id="scalarization-pass">Scalarization Pass</h2><span class="material-icons">link</span></a>
<p>This pass converts code that is already in a vector form into scalar code, or
retains a partially scalarized code, so that the packetizer can produce vector
IR at a vectorization width optimal for the target hardware.</p>
<p>The scalarization pass is divided into two stages: the analysis and the actual
transformation stage.</p>
<p>In the analysis we mark the values that need scalarization, which includes
vector leaves and non-vector instructions using vector operands.
The non-vector instructions using vector operands are either <code class="docutils literal notranslate">ExtractElement</code>s
with vector operands or <code class="docutils literal notranslate">BitCastInst</code>s from vector to non-vector. Note that the
analysis is not performed in an analysis pass, but a utility class that runs
locally within the transform pass, since this information is not needed by any
other pass.</p>
<p>If the vector leaf instruction or any of its arguments are of vector type and
the primitive size is greater than the partial scalarization factor (called
primitive size), the instruction is marked for needing scalarization. This marks
the end of analysis.</p>
<p>Once we have the values that were marked for transformation by the analysis
stage, the vector operands are first scalarized and then followed by the vector
leaf instructions that need scalarization.</p>
<blockquote>
<div><p>The utility classes can be found in
<code class="docutils literal notranslate">source/include/transform/scalarizer.h</code> and
<code class="docutils literal notranslate">source/transform/scalarizer.cpp</code>.
The transform pass can be found in
<code class="docutils literal notranslate">source/include/transform/scalarization_pass.h</code> and
<code class="docutils literal notranslate">source/transform/scalarization_pass.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="control-flow-conversion-pass">
<a class="header-link" href="#control-flow-conversion-pass"><h2 id="control-flow-conversion-pass">Control Flow Conversion Pass</h2><span class="material-icons">link</span></a>
<p>The control flow conversion linearizes the divergent control flow executing both
if and else condition blocks. In order to preserve safe access, the blocks are
predicated with masks, to allow only legal access for calls and memory accesses
that have side-effects.</p>
<p>Control flow conversion is the actual control-flow to data-flow conversion pass
that uses information from the control flow analysis and divergence analysis.
Conversion starts with generating masks, applying masks and generating selects,
followed by linearizing the control flow and finally repair the SSA form that
the linearization may have broken.</p>
<p>The mask for every basic block is generated starting with the entry mask, which
is followed by a branch mask for cases where the entry mask is a phi node of its
predecessors. Then special masks in the loop are generated to handle run time
control flow divergence, namely; the loop active mask, combined exit mask. Next,
the loop live values need to reflect the right values for early exited lanes.
The masks are then applied to prevent side-effects for the inactive instances.
In case of a call to memory operation, it is replaced with a corresponding masked
internal builtin call <a class="reference internal" href="#defining-internal-builtins"><span class="std std-doc">Defining Internal Builtins</span></a>.
The phi nodes are then transformed into selects, to enable control-flow to
data-flow conversion.</p>
<p>The CFG is then linearized, where necessary. It is actually partially linearized
to retain uniform branches that we know need not be linearized. We apply the
partial linearization by identifying every divergent blocks thanks to the
divergence analysis to know which blocks should be linearized, and which blocks
may remain untouched. A divergent block is called a <code class="docutils literal notranslate">div causing block</code>. To
linearize the CFG, we keep a deferral list that represents all the blocks that
lost their predecessor’s edge because of divergence. When we reach a block, if
the block is a div causing block, then it can only have one successor, otherwise
the block can keep the same amount of successors it has. To know which block
should be the successor of another block, we choose between the current
successors, and the deferral list available for that block. The choice is then
made based on the Dominance-Compact Block Indexing, which assigns each block a
unique index. Dominance compactness means that for any block, all other blocks
dominated by that block follow on in a contiguous sequence. This is constructed
by a depth-first traversal of the dominator tree, visiting children in CFG
reverse post-order. (In actual fact, Loop-Compactness takes precedence over
Dominance-Compactness; the latter usually implies the former, but certain loops
with multiple exits can break this, so special care has to be taken.) Using that
index to choose the successor guarantees that if an edge <code class="docutils literal notranslate">A to B</code> existed in the
original graph, an edge <code class="docutils literal notranslate">A to X to B</code> will exist in the linearized graph, thus
conserving dominance.</p>
<p>Once the CFG is linearized, we may have introduced new edges that were not there
previously, which may have broken the SSA form. Therefore, we must repair the
SSA form by introducing blend instructions (in the form of phi nodes) at the new
converging points.</p>
<p>The partial linearization implementation was inspired from the paper
<code class="docutils literal notranslate">Automatic SIMD Vectorization of SSA-based Control Flow Graphs</code> by
Ralf Karrenberg and <code class="docutils literal notranslate">Partial Control-Flow Linearization</code> by
Simon Moll &amp; Sebastian Hack.</p>
<blockquote>
<div><p>The pass can be found in
<code class="docutils literal notranslate">source/include/transform/control_flow_conversion_pass.h</code> and
<code class="docutils literal notranslate">source/transform/control_flow_conversion_pass.cpp</code>.</p>
</div></blockquote>
<div class="section" id="branch-on-superword-condition-code">
<a class="header-link" href="#branch-on-superword-condition-code"><h3 id="branch-on-superword-condition-code">Branch On Superword Condition Code</h3><span class="material-icons">link</span></a>
<p>Various optimizations directly linked to the partial linearization can be
applied. One of those optimizations is BOSCC (Branch On Superword Condition
Code), whose purpose is to duplicate predicated code into their uniform,
original, form so that this duplicated code can be executed when all lanes of
the SIMD group are either all true or all false. In fact, when this is the case,
there is no point to execute predicated instructions as all lanes will be
executed, or none.</p>
<p>The first step of this optimization is to duplicate all the code paths that may
diverge so that we can execute that code when all lanes are true/false. We thus
have one part of the CFG that diverges and one that stays uniform, throughout
the execution of the code. However, just after duplicating the code, the latter
is separated from the original CFG and the rewiring will be done later, once the
linearization is done. In order to identify which blocks need to be duplicated,
we need to identify Single-Entry, Single-Exit (SESE) regions that contain
divergence-causing branches. We leverage the Dominance-Compact Block Indexing to
do this, since any SESE region is necessarily dominance compact. In the simple
case, a divergence-causing branch will be from the entry block of a SESE region.
However, this is not strictly necessarily the case in more complex CFGs, where
the SESE entry block might not be a divergent branch, but multiple divergent
branches may exist within the region. Therefore we deal with Multiple-Entry,
Single-Exit predicated subregions of the SESE that can potentially overlap each
other (although we only ever duplicate each predicated block once, regardless of
how many different regions it appears in), each beginning with a single
divergence-causing branch.</p>
<p>Once the linearization is done, and we start repairing the CFG from all the
changes we made, we can start rewiring the duplicated (i.e. uniform) parts of
the CFG into the divergent ones. The first thing we do is to make the outermost
loop preheaders of duplicated loops always target the uniform loop because the
first time we enter the loop, all our lanes are activated/deactivated so there
is no need to execute the divergent loop. Then, for each divergent branch, we
add a run time checker that checks if all lanes are activated, in which case we
hit the all-lanes-activated uniform path. Otherwise, we check if none of the
lanes are activated, in which case we hit the no-lanes-activated uniform path.
Finally, if none of those two checks were true, then that means some condition
diverges: some lanes evaluate to true, and some evaluate to false; we thus have
to go into the divergent part of the CFG. As soon as we go into the divergent
part of the CFG (the one which contains predicated instructions), it is not
possible to go back into the uniform part of the CFG (the one that contains no
predicated instructions), until we reach a blend block, that is, a block where
all the previous divergent branches meet.</p>
<p>In order to allow fast reachability queries of the CFG, all of the blend points
are computed and stored during modification of the CFG, which allows us to
construct a data structure to speed up the required reachability queries at the
point the PHI nodes are actually created, since if we were modifying the CFG
during this process, the reachability data structre would be continuously
invalidated. It also means that the PHI nodes can be created with all
predecessors known, and avoids cases where a reachable PHI node would be falsely
classified as unreachable simply because it hasn’t been connected up yet.</p>
<p>Reachability queries are handled by the
<a class="reference internal" href="#reachability-analysis"><span class="std std-doc">Reachability Analysis</span></a> class described earlier in this
document, except in some remaining cases outside of BOSCC, and in one case
inside of BOSCC where reachability needs to traverse backedges, which is not
handled by the aforementioned data structure.</p>
<p>The BOSCC implementation was inspired from the paper
<code class="docutils literal notranslate">Predicate Vectors if you must</code> by Shahar Timnat, Ohad Shacham and Ayal Zaks.</p>
<blockquote>
<div><p>The class can be found in <code class="docutils literal notranslate">source/control_flow_boscc.h</code> and
<code class="docutils literal notranslate">source/control_flow_boscc.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="return-on-superword-condition-code">
<a class="header-link" href="#return-on-superword-condition-code"><h3 id="return-on-superword-condition-code">Return on Superword Condition Code</h3><span class="material-icons">link</span></a>
<p>ROSCC is a simpler alternative to BOSCC that doesn’t require any code
duplication. It handles only “early exit branches”, i.e. code of the form:</p>
<pre><code class="language-c">if (some_condition) {
  return;
}
</code>
</pre>
<p>Where <code class="docutils literal notranslate">some_condition</code> is a varying expression, ROSCC will insert an additional
uniform branch directly to the exit block.</p>
<p>ROSCC is applied only when BOSCC is turned off, since BOSCC will handle this
special case in a more general way.</p>
<blockquote>
<div><p>The class can be found in <code class="docutils literal notranslate">source/control_flow_roscc.h</code> and
<code class="docutils literal notranslate">source/control_flow_roscc.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="instantiating-functions-with-side-effects">
<a class="header-link" href="#instantiating-functions-with-side-effects"><h3 id="instantiating-functions-with-side-effects">Instantiating functions with side effects</h3><span class="material-icons">link</span></a>
<p>Much like the memory operations, functions that may produce side-effects also
need to be masked. Call instructions are examined, and if it is determined that
we will not be able to handle the call in any other way, the call is replaced
with a call to a masked version of the function.</p>
<p>The masked version is nothing more than a wrapper around the original call. The
wrapper function accepts the same arguments as the unmasked version and an
additional boolean (<code class="docutils literal notranslate">i8</code>) argument for the mask. If the mask is true, the
wrapped function is executed and its result is returned, otherwise  <code class="docutils literal notranslate">undef</code> is
returned, without executing the wrapped function.</p>
<p>After replacing the call with the masked call, we mark the call for
instantiation, as we cannot packetize it into a vector instruction.</p>
</div>
<div class="section" id="division-by-zero-exceptions">
<a class="header-link" href="#division-by-zero-exceptions"><h3 id="division-by-zero-exceptions">Division by zero exceptions</h3><span class="material-icons">link</span></a>
<p>On some hardware, a divide by zero operation and/or a numerical overflow will
result in a CPU exception. Since inactive vector lanes should never trigger such
an exception, masks may also need to be applied using <code class="docutils literal notranslate">select</code> instructions on
the divisor, that result in a divisor of <code class="docutils literal notranslate">1</code> for inactive lanes. There is no way
for Vecz to get the information about this requirement from the target, and since
most GPU hardware silently ignores division by zero, by default this behaviour is
disabled. It can be enabled explicitly by using the <code class="docutils literal notranslate">DivisionExceptions</code>
<a class="reference internal" href="#vecz-choices"><span class="std std-doc">Vecz Choice</span></a>.</p>
<p>Note that the mask applied to the divisor is derived purely from the CFG. The
behaviour of any division by zero on an active vector lane will be unaffected.</p>
</div>
</div>
<div class="section" id="packetization">
<a class="header-link" href="#packetization"><h2 id="packetization">Packetization</h2><span class="material-icons">link</span></a>
<p>During packetization, instructions that define varying values or produce varying
side-effects are turned into instructions that define the same value or produce
the same effects for each SIMD instance. For example, an <code class="docutils literal notranslate">add</code> instruction
that takes two <code class="docutils literal notranslate">i32</code> operands is turned into another <code class="docutils literal notranslate">add</code> instruction that
takes two <code class="docutils literal notranslate">&lt;N x i32&gt;</code> operands (where <code class="docutils literal notranslate">N</code> is the SIMD width). This is done
recursively in three steps; first, we packetize any branch condition that
requires packetization, and then, starting at the “vector leaves” of the
function, the rest of the instructions. Vector leaves are instructions that
allow varying values to “escape” from the function. Some examples of leaves
include:</p>
<ul class="simple">
<li><p>Store instructions, when the value to store and/or the pointer is varying</p></li>
<li><p>Call instructions, when varying operands are present or when the call has no
use</p></li>
<li><p>Return instructions</p></li>
</ul>
<p>After those two steps, then we proceed to packetize any remaining phi nodes,
explained in more details in a following <a class="reference internal" href="#packetizing-phi-nodes"><span class="std std-doc">subsection</span></a>.</p>
<p>During the packetization process, we might run into cases where we cannot
packetize a varying instruction but instead we have to instantiate it. By
instantiation we mean repeating an instruction <code class="docutils literal notranslate">N</code> times, one for each SIMD
lane. A common example would be calls to the <code class="docutils literal notranslate">printf</code> function, as in the
following kernel:</p>
<pre><code class="language-c">kernel void fn(global int *in, global int *out) {
  size_t tid = get_global_id(0);
  int load_in = in[tid];
  int result = load_in * tid;
  printf("in[%d] = %d\n", tid, result);
  out[tid] = result;
}
</code>
</pre>
<p>In this kernel, the call to the <code class="docutils literal notranslate">printf</code> function will be repeated <code class="docutils literal notranslate">N</code> times,
with its arguments adjusted to use the correct global ID for each lane. On the
other hand, the load and store instructions, as well as the multiplication, will
be packetized into vector instructions of width <code class="docutils literal notranslate">N</code>. More details on
instantiation can be found in the <a class="reference internal" href="#instantiation"><span class="std std-doc">relevant section</span></a>.</p>
<p>As we have already mentioned, the packetization (or instantiation) starts from
the vector leaves and recursively continues into their operands. As a matter of
fact, the operands are packetized before the instruction itself; in order to
generate the correct instruction, we first need to have the correct operands.
This process stops when we reach either:</p>
<ol class="simple">
<li><p>An operand that is uniform, such as constants or kernel arguments.</p></li>
<li><p>A vector root such as <code class="docutils literal notranslate">get_global_id(0)</code>.</p></li>
<li><p>A pointer that we can handle in its scalar form.</p></li>
</ol>
<p>In the first case, we create a packetized version of the operand by simply
broadcasting its value into a vector, so that each element of the vector
contains the same value. Since the value is uniform, we do not need to proceed
and packetize its operands. The second case is handled specially by using the
scalar value to create a vector of sequentially increasing values.</p>
<p>The third case is also special, because it depends on the access pattern
of the pointer. If the pointer is varying and we can determine a stride
to the access pattern then we do not need to packetize the pointer.
Instead, we can use the same pointer value as the base for a vector memory
instruction. More details on this can be found in the <a class="reference internal" href="#packetizing-memory-operations"><span class="std std-doc">Packetizing Memory
Operations</span></a> subsection.</p>
<p>Given all of these, we can now see how the example kernel given above will be
vectorized, with a vector width of 4. Of course, Vecz is not a source-to-source
transformation pass but the following kernel captures the equivalent IR changes
that will be performed in an easier to read format:</p>
<pre><code class="language-c">kernel void fn(global int *in, global int *out) {
  size_t tid = get_global_id(0);
  size_t4 tid4 = {tid, tid, tid, tid} + {0, 1, 2, 3};
  int4 load_in4 = in[tid];
  int4 result4 = load_in4 * tid4;
  printf("in[%d] = %d\n", tid4.s0, result4.s0);
  printf("in[%d] = %d\n", tid4.s1, result4.s1);
  printf("in[%d] = %d\n", tid4.s2, result4.s2);
  printf("in[%d] = %d\n", tid4.s3, result4.s3);
  out[tid] = result4;
}
</code>
</pre>
<p>Notice how the address for the vector load and store are still calculated using
the scalar ID variable (<code class="docutils literal notranslate">tid</code>), since the kernel accesses the elements of the
array consecutively and thus we can use a vector load and a vector store with
the same base address.</p>
<p>Regardless of how a varying instruction has been handled, after we have
packetized or instantiated it, we mark it for deletion. After we have gone
through all the vector leaves, we proceed to delete all the instructions that we
marked for deletion, as long as they have no remaining users.</p>
<blockquote>
<div><p>The packetization pass can be found in
<code class="docutils literal notranslate">source/include/transform/packetization_pass.h</code> and
<code class="docutils literal notranslate">source/transform/packetization_pass.cpp</code>.</p>
</div></blockquote>
<p>This is the general approach taken to packetize instructions but some cases
need to be handled specially. We will now explain in more depth some special
packetization cases.</p>
<div class="section" id="packetizing-memory-operations">
<a class="header-link" href="#packetizing-memory-operations"><h3 id="packetizing-memory-operations">Packetizing Memory Operations</h3><span class="material-icons">link</span></a>
<p>Memory operations are special as their access pattern determines how they are
packetized. Specifically, a memory operation will have one of these mutually
exclusive access patterns:</p>
<ol class="simple">
<li><p>No recognizable stride</p></li>
<li><p>A stride of 0 elements (i.e. being uniform)</p></li>
<li><p>A stride of 1 element (i.e. being contiguous)</p></li>
<li><p>A stride of <code class="docutils literal notranslate">X</code> elements</p></li>
</ol>
<p>In the first case we will packetize the memory operation using a scatter/gather
internal builtin. This means that we will generate an address for each SIMD
lane and the scatter/gather internal builtin will handle storing or loading the
elements to and from vectors.</p>
<p>In the second case, we will choose between two different approaches depending
on the need for masking. If masking is necessary, we will use masked
scatter/gather, with all the lanes getting the same address. If, on the other
hand, masking is not required, we will keep the scalar instruction and if it is
a load instruction, use a vector splat for the loaded value.</p>
<p>In the third case we could generate the addresses of the sequential elements and
use the same approach as in the first two but there is a much better solution.
All we need to do is perform a vector memory operation of width <code class="docutils literal notranslate">N</code> with the
same pointer as the scalar version of the instruction. This will efficiently
load <code class="docutils literal notranslate">N</code> elements from the memory into a vector. This is usually the most
optimal way to load and store vectors.</p>
<p>Finally, for the fourth case, we will use an interleaved memory operation
internal builtin. This builtin takes the base pointer and the stride of the
memory operation, so calculating each individual address is (in theory, see next
paragraph) not required.</p>
<p>How the internal builtins are implemented in practice differs based on the
target hardware but a description of the generic version emitted by Vecz can be
found in the <a class="reference internal" href="#defining-internal-builtins"><span class="std std-doc">Defining Internal Builtins</span></a> section.</p>
<blockquote>
<div><p>The relevant functions and classes can be found in
<code class="docutils literal notranslate">source/include/transform/memory_operations.h</code> and
<code class="docutils literal notranslate">source/transform/memory_operations.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="packetizing-phi-nodes">
<a class="header-link" href="#packetizing-phi-nodes"><h3 id="packetizing-phi-nodes">Packetizing Phi Nodes</h3><span class="material-icons">link</span></a>
<p>Phi nodes are a bit more tricky to packetize as they introduce cycles in the
def/use chain. To avoid this, an empty vector phi node (i.e. with no incoming
value) is created at first, when packetizing from the leaves. Once all the
leaves have been packetized, the incoming values of each empty phi is packetized
in turn. Since packetizing an incoming value may involve packetizing a new phi,
this process needs to be repeated until all phi nodes have been handled.</p>
</div>
<div class="section" id="packetizing-opencl-builtins">
<a class="header-link" href="#packetizing-opencl-builtins"><h3 id="packetizing-opencl-builtins">Packetizing OpenCL Builtins</h3><span class="material-icons">link</span></a>
<p>Since all the OpenCL builtins are known, we can use a special technique
for easily and efficiently packetizing many of them. Many of the builtins
already have vector equivalents, so we can just use them instead of
vectorizing the scalar version (for that approach see <a class="reference internal" href="#vectorizing-builtin-functions"><span class="std std-doc">Vectorizing Builtin
Functions</span></a> instead). This is done by first
determining if it is safe to use the vector equivalent. For example, the vector
version of the <code class="docutils literal notranslate">length</code> builtin does not operate element-wise, so we cannot use
it.</p>
<p>After we make sure that there are no known issues with the vector version of
the builtin, we construct the expected function signature based on the scalar
and the vector types that we have. We then search for the function matching
that signature in the current module, and also in the builtins module (if it is
available). If the function is found then we can use it, otherwise we report
that vectorizing the builtin failed. This means that this step can detect
builtins that have no vector versions but have been vectorized from the scalar
version using Vecz.</p>
<blockquote>
<div><p>The builtin information code can be found in
<code class="docutils literal notranslate">include/vecz/vecz_builtin_info.h</code>,
<code class="docutils literal notranslate">source/include/cl_builtin_info.h</code>, and
<code class="docutils literal notranslate">source/cl_builtin_info.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="instantiation">
<a class="header-link" href="#instantiation"><h3 id="instantiation">Instantiation</h3><span class="material-icons">link</span></a>
<p>Instantiating a value or instruction means evaluating it in the context of each
SIMD lane and creating a separate copy for each lane. Instantiating a call to
<code class="docutils literal notranslate">get_global_id(0)</code> or <code class="docutils literal notranslate">get_local_id(0)</code> results in the SIMD lane’s global or
local ID. If the instruction has varying operands, they need to be instantiated
(and so on recursively) too. Even though looking at the source code it looks as
if the instantiation is handled by a different pass, it is in the packetization
pass that calls for instructions to be instantiated when necessary. In turn, the
instantiator will call back in the packetization pass when it determines that it
shouldn’t instantiate an instruction.</p>
<p>When an instruction should be instantiated or not is determined by the
Instantiation Analysis. This analysis goes through all the instructions in the
function and looks for instructions that we know we shouldn’t try to packetize,
such as <code class="docutils literal notranslate">printf</code> calls, instructions that have types that we cannot create a
vector with, or the masked user functions we talked about in the <a class="reference internal" href="#control-flow-conversion-pass"><span class="std std-doc">Control Flow
Conversion</span></a> section.</p>
<blockquote>
<div><p>The analysis pass can be found in
<code class="docutils literal notranslate">source/include/analysis/instantiation_analysis.h</code> and
<code class="docutils literal notranslate">source/analysis/instantiation_analysis.cpp</code>.
The transform pass can be found in
<code class="docutils literal notranslate">source/include/transform/instantiation_pass.h</code> and
<code class="docutils literal notranslate">source/transform/instantiation_pass.cpp</code>.</p>
</div></blockquote>
<p>As an example of what instantiation looks like in the actual IR, let’s say that
we have the following code snippet that loads a variable:</p>
<pre><code class="language-c">... = in[get_global_id(0)]
</code>
</pre>
<p>The IR for the snippet looks like this:</p>
<pre><code class="language-default">%call = call spir_func i64 @_Z13get_global_idj(i32 0)
%arrayidx = getelementptr inbounds i32, i32 addrspace(1)* %in, i64 %call
%0 = load i32, i32 addrspace(1)* %arrayidx, align 4
</code>
</pre>
<p>If this code was to be instantiated, it would look like this:</p>
<pre><code class="language-default">%call = call spir_func i64 @_Z13get_global_idj(i32 0) #2
%arrayidx0 = getelementptr inbounds i32, i32 addrspace(1)* %in1, i64 %call, i64 0
%arrayidx1 = getelementptr inbounds i32, i32 addrspace(1)* %in1, i64 %call, i64 1
%arrayidx2 = getelementptr inbounds i32, i32 addrspace(1)* %in1, i64 %call, i64 2
%arrayidx3 = getelementptr inbounds i32, i32 addrspace(1)* %in1, i64 %call, i64 3
%0 = load i32, i32 addrspace(1)* %arrayidx0, align 4
%1 = load i32, i32 addrspace(1)* %arrayidx1, align 4
%2 = load i32, i32 addrspace(1)* %arrayidx2, align 4
%3 = load i32, i32 addrspace(1)* %arrayidx3, align 4
</code>
</pre>
<p>Note how each load takes a different memory address which depends on the SIMD
lane index and the current global ID.</p>
<p>Instantiation is usually done when a varying instruction cannot be packetized,
e.g. calls to functions like <code class="docutils literal notranslate">printf</code> which have no SIMD equivalent. The above
example does not require instantiation as the scalar load can simply be turned
into a vector load. The example was simply given for demonstration purposes, an
actual example can be found in the <a class="reference internal" href="#packetization"><span class="std std-doc">Packetization</span></a> section.</p>
</div>
<div class="section" id="vectorizing-builtin-functions">
<a class="header-link" href="#vectorizing-builtin-functions"><h3 id="vectorizing-builtin-functions">Vectorizing Builtin Functions</h3><span class="material-icons">link</span></a>
<p>Sometimes vectorizing kernels is not enough and the OpenCL builtin functions
called by the kernel have to be vectorized too. One example is <code class="docutils literal notranslate">isequal</code> which
returns <code class="docutils literal notranslate">1</code> if the two arguments have the same value or <code class="docutils literal notranslate">0</code> if they don’t or if
one of the argument is NaN. The IR implementation is simple:</p>
<pre><code class="language-default">define spir_func i32 @_Z7isequalff(float %x, float %y) {
entry:
  %cmp.i = fcmp oeq float %x, %y
  %conv.i = zext i1 %cmp.i to i32
  ret i32 %conv.i
}
</code>
</pre>
<p>The first step to vectorize this builtin function is declare the vectorized
builtin:</p>
<pre><code class="language-default">declare spir_func &lt;4 x i32&gt; @__vecz_v4__Z7isequalff(&lt;4 x float&gt; %x, &lt;4 x float&gt; %y)
</code>
</pre>
<p>The second step is to copy the instructions from the original function to the
vectorized function. One issue is that the function arguments now have type
<code class="docutils literal notranslate">&lt;4 x float&gt;</code> instead of <code class="docutils literal notranslate">float</code> which prevents copying instructions that
refer to the original arguments. One way to work around this is to create
<code class="docutils literal notranslate">extractelement</code> instructions to act as placeholders for the arguments.
Instructions that referred to the old arguments are changed to refer to the
relevant placeholder instead:</p>
<pre><code class="language-default">define spir_func &lt;4 x i32&gt; @__vecz_v4__Z7isequalff(&lt;4 x float&gt; %x, &lt;4 x float&gt; %y) {
entry:
  %placeholder_x = extractelement &lt;4 x float&gt; %x, i32 0
  %placeholder_y = extractelement &lt;4 x float&gt; %y, i32 0
  %cmp.i = fcmp oeq float %placeholder_x, %placeholder_y
  %conv.i = zext i1 %cmp.i to i32
  ret i32 %conv.i
}
</code>
</pre>
<p>Placeholders instructions are marked as such so that they are not mistaken with
regular instructions. When the placeholder needs to be packetized, it is
replaced with the actual argument:</p>
<pre><code class="language-default">define spir_func &lt;4 x i32&gt; @__vecz_v4__Z7isequalff(&lt;4 x float&gt; %x, &lt;4 x float&gt; %y) {
entry:
  %cmp.i1 = fcmp oeq &lt;4 x float&gt; %x, %y
  %conv.i2 = zext &lt;4 x i1&gt; %cmp.i1 to &lt;4 x i32&gt;
  ret &lt;4 x i32&gt; %conv.i2
}
</code>
</pre>
</div>
</div>
<div class="section" id="post-vectorization-optimizations-and-cleanup">
<a class="header-link" href="#post-vectorization-optimizations-and-cleanup"><h2 id="post-vectorization-optimizations-and-cleanup">Post-Vectorization Optimizations and Cleanup</h2><span class="material-icons">link</span></a>
<p>After the vectorization process is completed, we run some additional passes to
further optimize and cleanup the code:</p>
<ul class="simple">
<li><p>Inline Post Vectorization Pass (from Vecz)</p></li>
<li><p>CFG Simplification Pass (from LLVM)</p></li>
<li><p>Global Value Numbering Pass (from LLVM)</p></li>
<li><p>Dead Code Elimination Pass (from LLVM)</p></li>
<li><p>Interleaved Group Combining pass (from Vecz)</p></li>
<li><p>Instruction Combining pass (from LLVM)</p></li>
<li><p>Masked Memory Operations Simplification pass (from Vecz)</p></li>
<li><p>Internal Builtin Definition pass (from Vecz)</p></li>
</ul>
<blockquote>
<div><p>The passes can be found in the files
<code class="docutils literal notranslate">source/include/transform/passes.h</code> and
<code class="docutils literal notranslate">source/transform/passes.cpp</code>.</p>
</div></blockquote>
<div class="section" id="inline-post-vectorization-pass">
<a class="header-link" href="#inline-post-vectorization-pass"><h3 id="inline-post-vectorization-pass">Inline Post Vectorization Pass</h3><span class="material-icons">link</span></a>
<p>The Inline Post Vectorization Pass is responsible for inlining builtins that
have no vector/scalar equivalent or called functions that don’t have the
<code class="docutils literal notranslate">NoInline</code> attribute.</p>
</div>
<div class="section" id="interleaved-group-combining-pass">
<a class="header-link" href="#interleaved-group-combining-pass"><h3 id="interleaved-group-combining-pass">Interleaved Group Combining Pass</h3><span class="material-icons">link</span></a>
<p>The Interleaved Group Combining pass is responsible for lowering groups of
interleaved memory operations into vector memory operations. Specifically,
if there is a group of <code class="docutils literal notranslate">K</code> interleaved operations with stride <code class="docutils literal notranslate">K</code>, each
accessing the elements in between the others, they will be transformed into
<code class="docutils literal notranslate">K</code> consecutive vector operations. For example, if we have the interleaved
operations <em>A</em>, <em>B</em>, <em>C</em>, and <em>D</em> (with a number next to the letter signifying
the element index),</p>
<pre><code class="language-default">-------------------------------------------------
|A1|B1|C1|D1|A2|B2|C2|D2|A3|B3|C3|D3|A4|B4|C4|D4|
-------------------------------------------------
</code>
</pre>
<p>They will be optimized into the vector operations <em>a</em>, <em>b</em>, <em>c</em>, and <em>d</em>.</p>
<pre><code class="language-default">-------------------------------------------------
|a1|a2|a3|a4|b1|b2|b3|b4|c1|c2|c3|c4|d1|d2|d3|d4|
-------------------------------------------------
</code>
</pre>
<p>The first pattern commonly appears after scalarizing vector memory operations in
a kernel and then revectorizing each one of them into a vector instructions.</p>
<blockquote>
<div><p>The pass can be found in
<code class="docutils literal notranslate">source/include/transform/interleaved_group_combine_pass.h</code> and
<code class="docutils literal notranslate">source/transform/interleaved_group_combine_pass.cpp</code> while some of
the optimization code can be found in <code class="docutils literal notranslate">include/vecz_target_info.h</code>,
<code class="docutils literal notranslate">source/vector_target_info.cpp</code> and
<code class="docutils literal notranslate">source/vector_target_info_arm.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="masked-memory-operations-simplification-pass">
<a class="header-link" href="#masked-memory-operations-simplification-pass"><h3 id="masked-memory-operations-simplification-pass">Masked Memory Operations Simplification Pass</h3><span class="material-icons">link</span></a>
<p>This pass is responsible for lowering masked operations into unmasked or nop
operations, assuming that we can determine the mask values at compile time.
If all the lanes in the mask are set to <code class="docutils literal notranslate">true</code> then the mask is unnecessary
and the operation can be lowered to the equivalent unmasked operation. If,
on the other hand, all the mask lanes are set to <code class="docutils literal notranslate">false</code>, the operation will
not be executed at all and it can thus be replaced by a nop. Note that such
optimizations are only possible if the mask values are known at compile time, as
runtime optimizations need to be handled separately, specifically when the code
for the internal builtins is generated.</p>
<blockquote>
<div><p>The pass can be found in <code class="docutils literal notranslate">vectorizer.h</code> and <code class="docutils literal notranslate">vectorizer.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="defining-internal-builtins">
<a class="header-link" href="#defining-internal-builtins"><h3 id="defining-internal-builtins">Defining Internal Builtins</h3><span class="material-icons">link</span></a>
<p>We have already mentioned how the internal builtins are used in
the <a class="reference internal" href="#control-flow-conversion-pass"><span class="std std-doc">Control Flow Conversion</span></a> and
<a class="reference internal" href="#packetization"><span class="std std-doc">Packetization</span></a> sections. We have the following internal
builtins:</p>
<ul class="simple">
<li><p>masked load/store</p></li>
<li><p>interleaved load/store</p></li>
<li><p>masked interleaved load/store</p></li>
<li><p>scatter store / gather load</p></li>
<li><p>masked scatter store / gather load</p></li>
</ul>
<p>The masked versions perform the same operation as their unmasked counterparts,
with the exception that the operation is only performed for the lanes for which
the mask is <code class="docutils literal notranslate">true</code>.</p>
<p>For the masked loads and stores, as well as the masked scatter stores and gather
loads, LLVM provides intrinsics that perform these operations. How the
intrinsics are implemented obviously depends on the backend.</p>
<p>However, LLVM does not provide intrinsics for the remaining operations,
interleaved loads and stores, masked interleaved loads and stores, and unmasked
scatter stores and gather loads. Assuming that the masked scatter/gather
intrinsics that LLVM provides are at least as efficient as manually performing
each memory operation separately and then collecting them into a vector, we use
those LLVM intrinsics for these operations as well. For the interleaved
operations, we first need to generate all the pointers, using the pointer base
and the stride, and then call the LLVM intrinsic.</p>
<p>In case that intrinsic generation fails, we define the function by emulating the
vector with appropriate masking when required, which of course is suboptimal.</p>
<p>This design is the default used in Vecz but since it is modular, it is possible
to change the implementation for any target that Vecz is ported to.
Specifically, in the <code class="docutils literal notranslate">vector_target_info.cpp</code> file exists a number of
<code class="docutils literal notranslate">createX</code> functions (where <code class="docutils literal notranslate">X</code> is the internal builtin name, e.g.
“<code class="docutils literal notranslate">MaskedLoad</code>”) where the actual code for the builtins is generated. The
functions are very generic; they take an <code class="docutils literal notranslate">IRBuilder</code> and the required pointers
and values, so it is easy to modify them without having to modify any other part
of the vectorizer. Their code can be replaced with more optimal and target
specific code. It can also be modified to solve any issues the target might have
with the current internal builtins implementation.</p>
<blockquote>
<div><p>Note: The current implementation for scatter/gather uses an <code class="docutils literal notranslate">addrspacecast</code>
instruction in order to use the LLVM intrinsics with pointers having an
address space other than 0. This works for the x86 implementation but
it might not work on other architectures.</p>
<p>Note: The interleaved memory operations use the same fallback as the masked
interleaved ones.</p>
<p>The pass and the relevant materialization code can be found in
<code class="docutils literal notranslate">source/include/vectorization_context.h</code>,
<code class="docutils literal notranslate">source/vectorization_context.cpp</code>, <code class="docutils literal notranslate">include/vecz/vecz_target_info.h</code>,
and <code class="docutils literal notranslate">source/vector_target_info.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="cloning-of-the-opencl-metadata">
<a class="header-link" href="#cloning-of-the-opencl-metadata"><h3 id="cloning-of-the-opencl-metadata">Cloning of the OpenCL Metadata</h3><span class="material-icons">link</span></a>
<p>After the vectorization process has been completed, and only if it has been
successful, we update the OpenCL metadata in the module to include the
vectorized kernel. This isn’t done by a pass, it’s just a function call
at the end of the main vectorizer pass. Since some of the metadata requires
information known only by the frontend compiler (clang), we use the existing
metadata by cloning the relevant nodes and then replacing the function pointer.</p>
<blockquote>
<div><p>Note: When copying the metadata, we do not adjust the workgroup size, even
though we are now executing fewer work items. Since each invocation of the
kernel is now performing the work of <code class="docutils literal notranslate">N</code> scalar kernels, where <code class="docutils literal notranslate">N</code> the vector
width, we only need to execute <code class="docutils literal notranslate">1/N</code> work items for each workgroup.</p>
</div></blockquote>
</div>
</div>
<div class="section" id="miscellaneous">
<a class="header-link" href="#miscellaneous"><h2 id="miscellaneous">Miscellaneous</h2><span class="material-icons">link</span></a>
<p>This section covers various necessary utilities that the main vectorizer passes
are using.</p>
<div class="section" id="builtins-information">
<a class="header-link" href="#builtins-information"><h3 id="builtins-information">Builtins Information</h3><span class="material-icons">link</span></a>
<p>Vecz handles OpenCL builtins specially, so we need to be able to identify them,
query for various characteristics, and of course pull their definition or
implementation into the current module. This is all handled by the builtins info
code found in <code class="docutils literal notranslate">vecz_builtins_info.h</code>, <code class="docutils literal notranslate">cl_builtin_info</code>, and
<code class="docutils literal notranslate">cl_builtin_info.cpp</code>. The <code class="docutils literal notranslate">BuiltinInfo</code> class allows us to:</p>
<ul class="simple">
<li><p>Identify builtins based on their name.</p></li>
<li><p>Identify various characteristics of a builtin, such as if it safe to vectorize
it, or if it is a builtin we need to handle specially.</p></li>
<li><p>Determine if a builtin is uniform.</p></li>
<li><p>Determine if a builtin has side-effects.</p></li>
<li><p>Get the vector or scalar equivalent of a builtin.</p></li>
<li><p>Materialize a builtin from the builtins module.</p></li>
<li><p>Emit a custom inline implementation for specific builtins.</p></li>
</ul>
<p>While the code is mostly OpenCL centered, it can also handle LLVM intrinsics,
and it can be expanded to handle any builtin functions necessary.</p>
<p>As far as the identification of a builtin and its properties, parts of it are
done in a generic way that works with all the builtins, and parts are hardcoded
by the developers. For example, demangling a builtin and getting its name can be
easily done automatically, while determining if a builtin returns a global or
local ID needs to be hardcoded by the developers. For this reason, we have a
large list of known builtins that have a set of special characteristics, while
any builtin omitted from this list is assumed to conform to some default set of
characteristics.</p>
</div>
<div class="section" id="function-and-type-mangler-and-demangler">
<a class="header-link" href="#function-and-type-mangler-and-demangler"><h3 id="function-and-type-mangler-and-demangler">Function and Type Mangler and Demangler</h3><span class="material-icons">link</span></a>
<p>The SPIR standard mandates that all OpenCL builtins needs to be mangled
according to the Itanium name mangling convention, with some additional
extensions. Normally, the mangling of function names is handled by the frontend
of the compiler (clang), since it depends on language specific types but we can
correctly identify and mangle/demangle all the OpenCL primitives, vectors, and
image types at the IR level as well.</p>
<p>Mangling is used by the builtins module to determine the name of a newly
generated builtin (for example when creating the vector equivalent of a
builtin), while demangling is used to identify the builtins. Furthermore, other
parts of the vectorizer use the mangler/demangler for their own purposes.</p>
<p>Currently, we only support a subset of the Itanium mangling rules but this is
enough for most OpenCL kernels. For example, we cannot mangle <code class="docutils literal notranslate">struct</code> types, as
we cannot easily map between the C type name and the LLVM one.</p>
<blockquote>
<div><p>The relevant files are <code class="docutils literal notranslate">include/vecz/vecz_mangling.h</code> and
<code class="docutils literal notranslate">source/mangling.cpp</code>.</p>
</div></blockquote>
</div>
<div class="section" id="stride-and-offset-information">
<a class="header-link" href="#stride-and-offset-information"><h3 id="stride-and-offset-information">Stride and Offset Information</h3><span class="material-icons">link</span></a>
<p>As we explained in previous sections (<a class="reference internal" href="#packetization"><span class="std std-doc">Packetization</span></a>, <a class="reference internal" href="#defining-internal-builtins"><span class="std std-doc">Defining
Internal Builtins</span></a>), it is necessary for Vecz to be
able to determine the access pattern of a memory operation. This essentially
involves three attributes: the base pointer, the offset, and the stride.
These can be determined with the help of the <code class="docutils literal notranslate">OffsetInfo</code> class found in the
<code class="docutils literal notranslate">offset_info.h</code> and <code class="docutils literal notranslate">offset_info.cpp</code> files.</p>
<p>The class accepts a pointer and tries to determine the offset and the stride of
the pointer. This is done by tracing the base of the pointer and keeping track
of the operations performed on the way. As an example</p>
<pre><code class="language-c">kernel void fn(global int *in) {
  size_t tid = get_global_id(0);
  global int* ptr = (in + tid) * 2;
  ...
}
</code>
</pre>
<p>The <code class="docutils literal notranslate">ptr</code> pointer value in this kernel is calculated by adding the global ID to
it and then multiplying it by 2. Its base pointer is the <code class="docutils literal notranslate">in</code> kernel argument,
which is uniform. <code class="docutils literal notranslate">OffsetInfo</code> can determine that this pointer had an offset
depending on the global ID and that it has a stride of 2 elements (this is
similar to the scalar evolution analysis used for loop optimizations). Having
this information, we now know that any memory accesses using <code class="docutils literal notranslate">ptr</code> needs to be
packetized as interleaved memory operations with a stride of 2.</p>
</div>
<div class="section" id="vectorization-dimension">
<a class="header-link" href="#vectorization-dimension"><h3 id="vectorization-dimension">Vectorization Dimension</h3><span class="material-icons">link</span></a>
<p>User may decide to vectorize the code on whichever of the possible three
dimension the workgroup is composed of. Vecz refers to them as dimension <code class="docutils literal notranslate">0</code>
(x), dimension <code class="docutils literal notranslate">1</code> (y), and dimension <code class="docutils literal notranslate">2</code> (z). Vecz supports this configuration
via an additional parameter. This parameter directly affects the <a class="reference internal" href="#uniform-analysis"><span class="std std-doc">Uniform
Analysis</span></a>, the <a class="reference internal" href="#packetization"><span class="std std-doc">Packetization</span></a>, and the
<a class="reference internal" href="#stride-and-offset-information"><span class="std std-doc">Stride and Offset Information</span></a>. If no
parameter is specified, vectorization on the x dimension is assumed.</p>
</div>
<div class="section" id="vecz-choices">
<a class="header-link" href="#vecz-choices"><h3 id="vecz-choices">Vecz Choices</h3><span class="material-icons">link</span></a>
<p>“Choices” are options that the programmer can select regarding various aspects
of the vectorization process. For example, it is possible to set Vecz to always
vectorize uniform instructions. This is handled by the <code class="docutils literal notranslate">VectorizationChoices</code>
class. The choices can be set in three different ways:</p>
<ol class="simple">
<li><p>By modifying the code to explicitly enable or disable a choice. This is meant
to be used by developers when optimizing Vecz for a custom target.</p></li>
<li><p>By passing the <code class="docutils literal notranslate">-vecz-choice=&lt;Choice&gt;</code> flag to <code class="docutils literal notranslate">opt</code>. This is meant to be
used for testing and debugging purposes. More details for this option can be
found through <code class="docutils literal notranslate">opt</code>’s <code class="docutils literal notranslate">help</code> function.</p></li>
<li><p>By setting the <code class="docutils literal notranslate">CODEPLAY_VECZ_CHOICES</code> environment variable.</p></li>
<li><p>By calling the <code class="docutils literal notranslate">addChoice</code> method from the <code class="docutils literal notranslate">Vectorizer</code> class.</p></li>
</ol>
<p>The <code class="docutils literal notranslate">CODEPLAY_VECZ_CHOICES</code> variable accepts a string of Choices separated by
a semicolon (<code class="docutils literal notranslate">;</code>) character. More details, as well as the choices available, can
be found in the <code class="docutils literal notranslate">vecz_choices.h</code> file.</p>
<blockquote>
<div><p>The <code class="docutils literal notranslate">VectorizationChoices</code> class can be found in
<code class="docutils literal notranslate">include/vecz/vecz_choices.h</code> and
<code class="docutils literal notranslate">source/vectorization_choices.cpp</code></p>
</div></blockquote>
</div>
</div>
<div class="section" id="obtaining-vectorization-statistics">
<a class="header-link" href="#obtaining-vectorization-statistics"><h2 id="obtaining-vectorization-statistics">Obtaining Vectorization Statistics</h2><span class="material-icons">link</span></a>
<p>LLVM has support for collecting counters (called statistics in LLVM) from the
passes. Vecz is among the passes that can produce such information. This can be
done in two ways.</p>
<p>First, the official way is to use <code class="docutils literal notranslate">opt</code> with the <code class="docutils literal notranslate">-stats</code> option. This will
print the statistics from all the passes that have any.</p>
<p>The second way is to pass the <code class="docutils literal notranslate">-cl-llvm-stats</code> option to the oneAPI
Construction Kit. This will do pretty much the same work that the <code class="docutils literal notranslate">-stats</code>
option does, but it can be used in cases where it is not possible to use <code class="docutils literal notranslate">-stats</code>.</p>
</div>
<div class="section" id="optimization-remarks">
<a class="header-link" href="#optimization-remarks"><h2 id="optimization-remarks">Optimization Remarks</h2><span class="material-icons">link</span></a>
<p>Vecz utilizes the Remarks system available in LLVM, mostly to warn about
vectorization failures. The remarks can be enabled by passing the
<code class="docutils literal notranslate">-pass-remarks=vecz</code> and <code class="docutils literal notranslate">-pass-remarks-missed=vecz</code> command line option to
<code class="docutils literal notranslate">opt</code>, or the <code class="docutils literal notranslate">-v</code> flag to <code class="docutils literal notranslate">oclc</code>.</p>
</div>
<div class="section" id="veczc-the-vecz-compiler">
<a class="header-link" href="#veczc-the-vecz-compiler"><h2 id="veczc-the-vecz-compiler">veczc - the VECZ Compiler</h2><span class="material-icons">link</span></a>
<p>The command line tool veczc is a standalone compiler that is used to vectorize
LLVM bitcode binary files. Its main use is in our vecz LIT-based testing (see
modules/compiler/vecz/test).</p>
<p>It has the following arguments:</p>
<ul>
<li><p>-o <code class="docutils literal notranslate">file</code> output bitcode file</p></li>
<li><p>-w <code class="docutils literal notranslate">width</code> the width to vectorize the code to</p></li>
<li><p>-d <code class="docutils literal notranslate">dimension</code> the dimension index to vectorize the code on</p></li>
<li><p>-k <code class="docutils literal notranslate">name</code> the function names to select for vectorization. It can appear
multiple times, in one of several forms. In the standard form, simply passing
the names of kernels will ensure those kernels are vectorized by the globally
selected parameters
e.g.
<code class="docutils literal notranslate">veczc -k foo -k bar ...</code>
selects both the <code class="docutils literal notranslate">foo</code> and <code class="docutils literal notranslate">bar</code> kernels for
vectorization.
The more complex form allows specifying the vectorization parameters
<em>per</em>-kernel in multiplicate:
e.g.
<code class="docutils literal notranslate">veczc -k foo:4,8,16 ...</code>
will generate multiple vectorized versions of <code class="docutils literal notranslate">foo</code> at vectorization factors
of 4, 8, and 16. All other paremeters will be inherited from the global
configuration.
The complete syntax for the kernel specification switch (<code class="docutils literal notranslate">k</code>) value is as follows:</p>
<pre><code class="language-bnf">&lt;kernel_spec&gt; ::= &lt;kernel_name&gt; ':' &lt;spec&gt;
&lt;kernel_spec&gt; ::= &lt;kernel_name&gt;
&lt;spec&gt; ::= &lt;vf&gt;&lt;dimension&gt;(opt)&lt;width&gt;(opt)&lt;scalable_spec&gt;(opt)&lt;auto&gt;(opt)
&lt;spec&gt; ::= &lt;spec&gt; ',' &lt;spec&gt; // multiple specs are comma-separated
&lt;number&gt; ::= [0-9]+ // a decimal integer
&lt;kernel_name&gt; ::= [a-zA-Z_][a-zA-Z_0-9]+ // As in the simple form - the name of the kernel to vectorize
&lt;dim&gt; ::= '.' [123] // Vectorize only the given dimension
&lt;vf&gt; ::= &lt;number&gt; // vectorize by the given factor
&lt;vf&gt; ::= 'a' // automatic vectorization factor
&lt;simd_width&gt; ::= '@' &lt;number&gt; // Assume local size (SIMD width) is the given number
&lt;scalable_spec&gt; ::= 's' // Turn on scalable vector support
</code>
</pre>
<p>n.b. (There should be no whitespace as this interface is designed for easy
nonquoted use in common shells)</p>
</li>
</ul>
<p>It supports bitcode files with the following target triples:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate">spir-unknown-unknown</code> 32-bit SPIR binaries</p></li>
<li><p><code class="docutils literal notranslate">spir64-unknown-unknown</code> 64-bit SPIR binaries</p></li>
</ul>
<p>Because veczc doesn’t load all of the builtins prior to vectorization,
declarations of scalar or vector versions of any builtins used in the input file
must be present, otherwise scalarization or packetization will not be able to
materialize the scalarized/vectorized builtin calls and veczc will fail with an
error message.</p>
</div>
<div class="section" id="references">
<a class="header-link" href="#references"><h2 id="references">References</h2><span class="material-icons">link</span></a>
</div>
</div>
</div>
</div></body>
<!-- Mirrored from 127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/vecz/vecz by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 22 Sep 2025 18:52:46 GMT -->
</html>
                    <a id="bottom"></a>
                </div>

                <!-- Separator -->
                <div class="separator"></div>

                <!-- Rate -->
                <div id="rate" class="rate collapsed">
                    <div>
                        Rate this Guide
                    </div>
                    <form action="https://formspree.io/f/xzbypbvl" method="post">
                        <input type="hidden" name="subject" value="Guide Feedback" />
                        <input type="hidden" name="product" value="oneAPI" />
                        <input type="hidden" name="variant" value="Construction Kit" />
                        <input type="hidden" name="guide" value="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/vecz/vecz" />

                        <div class="up" title="Thumb up this guide">
                           <i class="material-icons">thumb_up</i>
                       </div>
                        <div class="down" title="Thumb down this guide">
                            <i class="material-icons">thumb_down</i>
                        </div>
                        <div>
                            <input type="text" name="message"
                                   required="required"
                                   minlength="3"
                                   maxlength="1000"
                                   placeholder="How can we improve this guide? (press enter to send)" />
                        </div>
                    </form>
                </div>

                <!-- Separator -->
                <div class="separator"></div>

                <!-- Navigator -->
                <div id="navigator">
                    <div>
                        <a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/vecz#bottom"
                            >
                            <div>
                                <i class="material-icons">navigate_before</i>
                            </div>
                            <div>
                                <h1>Vecz</h1>
                            </div>
                        </a>
                    </div>
                    <div>
                        <a href="http://127.0.0.1/products/oneapi/construction-kit/4.0.0/guides/modules/spirv-ll"
                            >
                            <div>
                                <h1>spirv-ll</h1>
                            </div>
                            <div>
                                <i class="material-icons">navigate_next</i>
                            </div>
                        </a>
                    </div>
                </div>
            </article>

            <!-- Separator -->
            <div class="separator"></div>

            <!-- Footer Target -->
            <div id="footer-target"></div>
        </div>

        <!-- File Jump List -->
        <div id="jump-list-container" class="sticky styled-scroller">
            <div class="nav-padding">
                <div class="jump-list-container">
                    <h1 class="file-container-title">
                        <span class="material-icons">assignment</span>Jump to Section
                    </h1>
                    <ol class="in-page-jump-list">
                        <li class="heading-1"><a href="#vecz-documentation">Vecz Documentation</a></li>
                        <li class="heading-2"><a href="#design-ideas">Design ideas</a></li>
                        <li class="heading-2"><a href="#supporting-infrastructure">Supporting infrastructure</a></li>
                        <li class="heading-2"><a href="#target-specialization">Target specialization</a></li>
                        <li class="heading-2"><a href="#vectorization-process">Vectorization process</a></li>
                        <li class="heading-2"><a href="#uniform-analysis">Uniform Analysis</a></li>
                        <li class="heading-2"><a href="#stride-analysis">Stride Analysis</a></li>
                        <li class="heading-2"><a href="#packetization-analysis">Packetization Analysis</a></li>
                        <li class="heading-2"><a href="#control-flow-graph-analysis">Control Flow Graph Analysis</a></li>
                        <li class="heading-2"><a href="#divergence-analysis">Divergence Analysis</a></li>
                        <li class="heading-2"><a href="#liveness-analysis">Liveness Analysis</a></li>
                        <li class="heading-2"><a href="#simd-width-analysis">SIMD Width Analysis</a></li>
                        <li class="heading-2"><a href="#vectorizability-analysis">Vectorizability Analysis</a></li>
                        <li class="heading-2"><a href="#reachability-analysis">Reachability Analysis</a></li>
                        <li class="heading-2"><a href="#preparation-passes">Preparation Passes</a></li>
                        <li class="heading-2"><a href="#remove-intptr-pass">Remove Intptr Pass</a></li>
                        <li class="heading-2"><a href="#squash-small-vectors-pass">Squash Small Vectors Pass</a></li>
                        <li class="heading-2"><a href="#scalarization-pass">Scalarization Pass</a></li>
                        <li class="heading-2"><a href="#control-flow-conversion-pass">Control Flow Conversion Pass</a></li>
                        <li class="heading-2"><a href="#packetization">Packetization</a></li>
                        <li class="heading-2"><a href="#post-vectorization-optimizations-and-cleanup">Post-Vectorization Optimizations and Cleanup</a></li>
                        <li class="heading-2"><a href="#miscellaneous">Miscellaneous</a></li>
                        <li class="heading-2"><a href="#obtaining-vectorization-statistics">Obtaining Vectorization Statistics</a></li>
                        <li class="heading-2"><a href="#optimization-remarks">Optimization Remarks</a></li>
                        <li class="heading-2"><a href="#veczc-the-vecz-compiler">veczc - the VECZ Compiler</a></li>
                        <li class="heading-2"><a href="#references">References</a></li>
                    </ol>
                </div>
            </div>
        </div>
    </div>
</div>
<!-- Handle layout resizing here to avoid jumping -->
<script nonce="cff47b03734500a4657c90b6b8e3ab84">
    const resizerCookie = getCookie('CDPRESIZER');
    if (resizerCookie) {
        const cookieValue = JSON.parse(resizerCookie);

        for (let [key, value] of Object.entries(cookieValue)) {
            if (value === null || value === undefined) {
                continue;
            }

            key = atob(key);
            $(':root')[0].style.setProperty('--' + key, value + 'px');
        }
    }
</script>

</main>

<!-- Product Selector-->
<div id="productSelectorDialog" class="popupDialog">
    <div class="side-by-side-panel panel">
        <div id="products">
            <div>
                <h1>Select a Product</h1>
            </div>
            <ul>
                <li>
                    <a class="productSelection oneapi" data-product="oneapi">
                        oneAPI
                    </a>
                </li>
            </ul>
        </div>
        <div id="product-selection">
            <div id="no-product">
                Please select a product
            </div>
            <div id="product">
                <div id="product-oneapi" class="product-view">
                    <h1>

                        oneAPI
                    </h1>
                    <p>oneAPI is a cross-industry, open, standards-based unified programming model that delivers a common developer experience across accelerator architecture - for faster application performance, more productivity, and greater innovation.</p>
                    <ul id="variants">
                        <li>
                            <a href="http://127.0.0.1/products/oneapi/construction-kit/">
                                <div>
                                    Construction Kit
                                </div>
                                <div>
                                    <i class="material-icons">arrow_right</i>
                                </div>
                            </a>
                        </li>
                        <li>
                            <a href="http://127.0.0.1/products/oneapi/amd/">
                                <div>
                                    for AMD GPU
                                </div>
                                <div>
                                    <i class="material-icons">arrow_right</i>
                                </div>
                            </a>
                        </li>
                        <li>
                            <a href="http://127.0.0.1/products/oneapi/nvidia/">
                                <div>
                                    for NVIDIA® GPUs
                                </div>
                                <div>
                                    <i class="material-icons">arrow_right</i>
                                </div>
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Color Scheme Selector-->
<div id="colorSchemeDialog" class="popupDialog">
    <div>
        <div class="selectDarkMode">
            <div>
                <img src="http://127.0.0.1/assets/img/darkmode.png" alt="Dark Mode" />
            </div>
            <div>
                <i class="material-icons">brightness_2</i>
                <h1>Dark Mode</h1>
                <p>Light text on a dark background.</p>
            </div>
        </div>
        <div class="selectLightMode">
            <div>
                <img src="http://127.0.0.1/assets/img/lightmode.png" alt="Light Mode" />
            </div>
            <div>
                <i class="material-icons">lightbulb_outline</i>
                <h1>Light Mode</h1>
                <p>Dark text on a light background.</p>
            </div>
        </div>
    </div>
</div>

<!-- Site Selector -->
<div id="siteSelectorDialog" class="popupDialog">
    <div class="panel" id="profile-panel">
        <header>
            <div>
                <i class="material-icons">public</i>
            </div>
            <div>
                <h1>Also,</h1>
                <h2>part of our network</h2>
            </div>
        </header>
        <ul>
            <li>
                <a href="https://www.codeplay.com/" target="_blank" rel="nofollow noopener noreferrer">
                    <h1>Codeplay.com</h1>
                    <p>Find out about Codeplay, the latest company news and blog posts.</p>
                </a>
            </li>
            <li>
                <a href="https://www.sycl.tech/" target="_blank" rel="nofollow noopener noreferrer">
                    <h1>SYCL.tech</h1>
                    <p>Find out about the latest SYCL news, videos and projects.</p>
                </a>
            </li>
            <li class="selected">
                <a>
                    <img src="http://127.0.0.1/assets/img/you-are-here.png" alt="You Are Here Logo" />
                    <h1>Codeplay Developer</h1>
                    <p>Get the latest documentation and release packages for ComputeCpp and ComputeSuite</p>
                </a>
            </li>
            <li>
                <a href="https://github.com/codeplaysoftware" target="_blank" rel="nofollow noopener noreferrer">
                    <h1>Codeplay Open Source</h1>
                    <p>Browse our open source projects and frameworks on GitHub.</p>
                </a>
            </li>
        </ul>
    </div>
</div>

<!-- Footer section -->
<footer class="section-padding">
    <div class="content-wrapper">
        <div>
            <h1>&copy; Codeplay Software Ltd</h1>
            <div id="copyright"></div>
        </div>
        <div>
            <ul>
                <li><a href="https://codeplay.com/" target="_blank" rel="noopener">
                    Visit codeplay.com</a></li>
                <li><a href="https://codeplay.com/company/privacy/" target="_blank" rel="noopener">
                    View Our Privacy Policy</a></li>
                <li><a href="http://127.0.0.1/cookies/">
                    Read Our Cookie Policy</a></li>
            </ul>
        </div>
    </div>
</footer>

</body>
</html>